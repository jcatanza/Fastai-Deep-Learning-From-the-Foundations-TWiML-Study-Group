{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a MNIST data processing pipeline using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all code from previous notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_03 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the MNIST training and validation data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=4799)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()\n",
    "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
    "n_hidden,batch_size = 50,64\n",
    "# number of output classes\n",
    "#     for MNIST, one class for each digit\n",
    "n_out = y_train.max().item()+1\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 784])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# data set properties x and y come from Dataset\n",
    "print(valid_ds.x.shape)\n",
    "print(valid_ds.y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Improving the fit() function\n",
    "\n",
    "Currently, a call to `fit()` has many inputs\n",
    "\n",
    "`fit(model, loss_func, opt, train_dl, valid_dl, n_epochs, )`\n",
    "\n",
    "We can simplify the call to `fit()` to look like this:\n",
    "\n",
    "`fit(learner, n_epochs)`\n",
    "\n",
    "where `learner` is a `Learner` Class object, that we will define as a container for the `model`, `loss_func`, `opt`, `train_dl`, `valid_dl` inputs to be passed into `fit()`\n",
    "\n",
    "This will allow us to tweak what's happening inside the training loop in other places of the code. Because the `Learner` Class object will be mutable, changing any of its attributes elsewhere will modify our training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=5363)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The DataBunch class\n",
    "For convenience we define a `DataBunch()` class, as a container for the DataLoader() objects and optionally n_out, the number of output channels.\n",
    "DataBunch() takes inputs train_dl(), valid_dl(), and optionally n_out.\n",
    "It has properties train_ds(), valid_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataBunch():\n",
    "    def __init__(self, train_dl, valid_dl, n_out=None):\n",
    "        self.train_dl,self.valid_dl,self.n_out = train_dl,valid_dl,n_out\n",
    "    \n",
    "    # add train_ds() as an attribute\n",
    "    @property\n",
    "    def train_ds(self): return self.train_dl.dataset\n",
    "     \n",
    "        \n",
    "    # add valid_ds() as an attribute\n",
    "    @property\n",
    "    def valid_ds(self): return self.valid_dl.dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Learner Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# instantiates the model and the optimizer, given the data and parameters\n",
    "def get_model(data, learning_rate=0.5, n_hidden = 50):\n",
    "    n_columns = data.train_ds.x.shape[1]\n",
    "    n_out = data.n_out\n",
    "    model = nn.Sequential(nn.Linear(n_columns,n_hidden), nn.ReLU(), nn.Linear(n_hidden,n_out))\n",
    "    # Q: why can we access the optimizer from within this function?\n",
    "    return model, optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# the Learner() class is a container for the model, optimization, loss function and data \n",
    "class Learner():\n",
    "    def __init__(self, model, opt, loss_func, data):\n",
    "        self.model,self.opt,self.loss_func,self.data = model,opt,loss_func,data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1A. Refactor the fit() function according to plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refactor the fit() function according to our plan\n",
    "#     Note the order of the inputs has been switched in order to allow n_epochs to be a keyword argument\n",
    "def fit(learn,n_epochs):\n",
    "    \n",
    "    # n_epochs is a keyword argument\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # training phase\n",
    "        learn.model.train()\n",
    "        for xb,yb in learn.data.train_dl:\n",
    "            pred = learn.model(xb)\n",
    "            loss = learn.loss_func(pred, yb)\n",
    "            loss.backward()\n",
    "            learn.opt.step()\n",
    "            learn.opt.zero_grad()\n",
    "\n",
    "        # prediction phase\n",
    "        # tells pytorch that we are in eval phase, so no dropout, batchnorm, etc.\n",
    "        learn.model.eval()\n",
    "        # accumulate loss and accuracy over batches\n",
    "        with torch.no_grad():\n",
    "            tot_loss,tot_acc = 0.,0.\n",
    "            for xb,yb in learn.data.valid_dl:\n",
    "                pred = learn.model(xb)\n",
    "                tot_loss += learn.loss_func(pred, yb)\n",
    "                tot_acc  += accuracy(pred,yb)\n",
    "        \n",
    "        # compute average loss and accuracy\n",
    "        n_valid = len(learn.data.valid_dl)\n",
    "        avg_loss, avg_acc = tot_loss/n_valid, tot_acc/n_valid\n",
    "        print(epoch, avg_loss ,avg_acc )\n",
    "        \n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1B. Prepare for minibatch training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### package up the data into a DataBunch object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 784])\n",
      "torch.Size([50000])\n"
     ]
    }
   ],
   "source": [
    "# package up the data in a DataBunch object\n",
    "# the * forces you to generate and process the entire sample\n",
    "batch_size = 64\n",
    "n_out = y_train.max().item()+1\n",
    "data = DataBunch(*get_dls(train_ds, valid_ds, batch_size=batch_size), n_out=n_out)\n",
    "\n",
    "# data also has properties x and y, inherited from train_ds\n",
    "print(data.train_dl.dataset.x.shape)\n",
    "print(data.train_dl.dataset.y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lengths of the training and validation dataloaders are the number of batches in the training and validation data sets, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782 79\n",
      "50048 10112\n"
     ]
    }
   ],
   "source": [
    "print(len(data.train_dl), len(data.valid_dl))\n",
    "print(len(data.train_dl)*batch_size, len(data.valid_dl)*2*batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### package up the model, opt, loss_func, and data in a Learner Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a Learner object\n",
    "learn = Learner(*get_model(data), loss_func, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# check module list outputs\n",
    "print(learn.model.train())\n",
    "print(learn.model.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1C. Instantiate a minibatch training loop and train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.1808) tensor(0.9437)\n"
     ]
    }
   ],
   "source": [
    "# instantiate a minibatch training loop and start training!\n",
    "loss,acc = fit(learn, n_epochs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Adding callbacks \n",
    "Callbacks are functions that can be set to initiate desired sequences of actions at various stages in the minibatch training process. They will allow us to simplify the training loop, and provide added flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our training loop (without validation) from the previous notebook, with the inner loop contents factored out:\n",
    "\n",
    "```python\n",
    "def one_batch(xb,yb):\n",
    "    pred = model(xb)\n",
    "    loss = loss_func(pred, yb)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "def fit():\n",
    "    for epoch in range(n_epochs):\n",
    "        for b in train_dl: one_batch(*b)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=5628)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CallBack() Class\n",
    "\n",
    "Is a container for a set of nine basic callback methods.\n",
    "\n",
    "Each method is associated with a well-defined stage in the training process, and returns `True` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback():\n",
    "    def begin_fit(self, learn):\n",
    "        self.learn = learn\n",
    "        return True\n",
    "    def after_fit(self):\n",
    "        return True\n",
    "    def begin_epoch(self, epoch):\n",
    "        self.epoch_number=epoch\n",
    "        return True\n",
    "    def begin_validate(self):\n",
    "        return True\n",
    "    def after_epoch(self): \n",
    "        return True\n",
    "    def begin_batch(self, xb, yb):\n",
    "        self.xb,self.yb = xb,yb\n",
    "        return True\n",
    "    def after_loss(self, loss):\n",
    "        self.loss = loss\n",
    "        return True\n",
    "    def after_backward(self):\n",
    "        return True\n",
    "    def after_step(self):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CallbackHandler Class\n",
    "\n",
    "is a container for a collection of methods comprised of\n",
    "\n",
    "    (1) a \"wrapper\" for each method in the Callback() class \n",
    "\n",
    "    (2) a do_stop() method that can set the learn.stop flag\n",
    "    \n",
    "takes a list of Callback() objects  as input\n",
    "\n",
    "each \"wrapper\" modifies the behavior of its associated callback, and returns a state flag, as follows:\n",
    "    - initialize the state flag\n",
    "    - optionally set some object properties and/or run some methods\n",
    "    - for each Callback() object in the input list:\n",
    "      check whether the callback is among its methods \n",
    "         if so, execute the callback, and\n",
    "            if the callback returns True, set the state flag to its initialized value\n",
    "            if the callback returns False, set the state flag to False\n",
    "         if not, set the state flag to False\n",
    "    - return the state flag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallbackHandler():\n",
    "    def __init__(self,callbacks=None):\n",
    "        self.callbacks = callbacks if callbacks else []\n",
    "\n",
    "    def begin_fit(self, learn):\n",
    "        self.learn,self.in_train = learn,True\n",
    "        learn.stop = False\n",
    "        state = True\n",
    "        for callback in self.callbacks: \n",
    "            state = state and callback.begin_fit(learn)\n",
    "        return state\n",
    "\n",
    "    def after_fit(self):\n",
    "        state = not self.in_train\n",
    "        for callback in self.callbacks: \n",
    "            state = state and callback.after_fit()\n",
    "        return state\n",
    "    \n",
    "    def begin_epoch(self, epoch):\n",
    "        # the next line trains the model\n",
    "        self.learn.model.train()\n",
    "        self.in_train=True\n",
    "        state = True\n",
    "        for callback in self.callbacks: \n",
    "            state = state and callback.begin_epoch(epoch)\n",
    "        return state\n",
    "\n",
    "    def begin_validate(self):\n",
    "        # what does the next line do?\n",
    "        self.learn.model.eval()\n",
    "        self.in_train=False\n",
    "        state = True\n",
    "        for callback in self.callbacks: \n",
    "            state = state and callback.begin_validate()\n",
    "            print('begin_validate state ',state)\n",
    "            print('self.learn.stop ',self.learn.stop)\n",
    "        return state\n",
    "\n",
    "    def after_epoch(self):\n",
    "        state = True\n",
    "        for callback in self.callbacks: \n",
    "            state = state and callback.after_epoch()\n",
    "        return state\n",
    "    \n",
    "    def begin_batch(self, xb, yb):\n",
    "        state = True\n",
    "        for callback in self.callbacks:\n",
    "            state = state and callback.begin_batch(xb, yb)\n",
    "        return state\n",
    "\n",
    "    def after_loss(self, loss):\n",
    "        state = self.in_train\n",
    "        for callback in self.callbacks: \n",
    "            state = state and callback.after_loss(loss)\n",
    "        return state\n",
    "\n",
    "    def after_backward(self):\n",
    "        state = True\n",
    "        for callback in self.callbacks: \n",
    "            state = state and callback.after_backward()\n",
    "        return state\n",
    "\n",
    "    def after_step(self):\n",
    "        state = True\n",
    "        for callback in self.callbacks: \n",
    "            state = state and callback.after_step()\n",
    "        return state\n",
    "    \n",
    "    def do_stop(self):\n",
    "        try:     \n",
    "            return self.learn.stop\n",
    "        finally: \n",
    "            self.learn.stop = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A TestCallback Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(Callback):\n",
    "    \n",
    "    # Q: does the begin_fit() callback below inherit from \n",
    "    #     the Callback() class, or \n",
    "    #     from the CallbackHandler() class? \n",
    "    # A: I think from the Callback() class\n",
    "\n",
    "    # modify the begin_fit() callback \n",
    "    #     add iteration, batch and epoch counters\n",
    "    def begin_fit(self,learn):\n",
    "        # calls begin_fit() method from the Callback class\n",
    "        super().begin_fit(learn)\n",
    "        max_iter = 10\n",
    "        self.max_iter = max_iter\n",
    "        self.n_iter = 0\n",
    "        self.n_epoch_float = 0.\n",
    "        self.n_batch = 0\n",
    "        return True\n",
    "    \n",
    "    # after each step update in the first batch, begin_batch is executed\n",
    "    #     but once n_iter reaches 10, learn.stop is set, and after_step never executes again, because\n",
    "    #     the program exits the training loop and the validation data is then processed\n",
    "    #def begin_batch(self,xb,yb):\n",
    "    #    super().begin_batch(xb,yb)\n",
    "    #    print('n_iter = ',self.n_iter,' validate = ',self.begin_validate(),'learn.stop = ',self.learn.stop)\n",
    "    #    return True\n",
    "    \n",
    "    # modify the afer_step() callback to increment the iteration counter, print the current iteration number,\n",
    "    #   and to set the learn.stop flag to True after max_iter iterations is reached\n",
    "    # Q: why doesn't after_step() inherit from its previous definition, as we did with begin_fit()?\n",
    "    # A: because the previous after_step() does nothing but return True\n",
    "    def after_step(self):\n",
    "        self.n_iter += 1\n",
    "        if self.n_iter >= self.max_iter: \n",
    "            self.learn.stop = True\n",
    "        print('parameter update iteration number ',self.n_iter,'batch_number ',self.n_batch,' learn.stop = ',self.learn.stop)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor the training loop using callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process a single batch, with an input list of callbacks\n",
    "def one_batch(xb, yb, callback):\n",
    "    \n",
    "    # Q: how do parameter updates happen within a batch?\n",
    "        \n",
    "    # check for exit condition\n",
    "    # Q: when would this condition be True?\n",
    "    if not callback.begin_batch(xb,yb): \n",
    "        print('exiting from one_batch due to begin_batch...')\n",
    "        return\n",
    "    \n",
    "    # run the model and compute the loss function for the current batch\n",
    "    loss = callback.learn.loss_func(callback.learn.model(xb), yb)\n",
    "    \n",
    "    print('executing one_batch...')\n",
    "    \n",
    "    # do backpropagation for the current batch if in training mode, otherwise exit here\n",
    "    if not callback.after_loss(loss): \n",
    "        print('exiting from one_batch due to after_loss...')\n",
    "        return\n",
    "    loss.backward()\n",
    "    \n",
    "    # update the parameters for the current batch\n",
    "    if callback.after_backward(): \n",
    "        callback.learn.opt.step()\n",
    "        \n",
    "    # zero the gradients to prepare for the next batch\n",
    "    if callback.after_step(): \n",
    "        callback.learn.opt.zero_grad()\n",
    "        \n",
    "# process the entire dataset, with an input list of callbacks\n",
    "#   (i.e. loop through all the batches)\n",
    "def all_batches(dataloader, callback):\n",
    "    for xb,yb in dataloader:\n",
    "        \n",
    "        # process a batch\n",
    "        one_batch(xb, yb, callback)\n",
    "        \n",
    "        # check whether to stop or to process the next batch\n",
    "        if callback.do_stop(): \n",
    "            return\n",
    "\n",
    "# training loop with an input callback\n",
    "def fit(learn, callback, n_epochs):\n",
    "    \n",
    "    # check whether or not to start the training loop\n",
    "    if not callback.begin_fit(learn): \n",
    "        return\n",
    "    \n",
    "    # loop over the specified number of epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # check whether or not to process the next epoch\n",
    "        if not callback.begin_epoch(epoch): \n",
    "            continue # jumps to next epoch\n",
    "        all_batches(learn.data.train_dl, callback)\n",
    "        \n",
    "        # check whether or not to process the validation set\n",
    "        if callback.begin_validate():\n",
    "            with torch.no_grad(): \n",
    "                all_batches(learn.data.valid_dl, callback)\n",
    "        \n",
    "        # check whether or not to break after the current epoch has been processed\n",
    "        if callback.do_stop() or not callback.after_epoch(): \n",
    "            break\n",
    "            \n",
    "    # set the callback state to indicate that fit() has been run\n",
    "    callback.after_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing one_batch...\n",
      "parameter update iteration number  1 batch_number  0  learn.stop =  False\n",
      "executing one_batch...\n",
      "parameter update iteration number  2 batch_number  0  learn.stop =  False\n",
      "executing one_batch...\n",
      "parameter update iteration number  3 batch_number  0  learn.stop =  False\n",
      "executing one_batch...\n",
      "parameter update iteration number  4 batch_number  0  learn.stop =  False\n",
      "executing one_batch...\n",
      "parameter update iteration number  5 batch_number  0  learn.stop =  False\n",
      "executing one_batch...\n",
      "parameter update iteration number  6 batch_number  0  learn.stop =  False\n",
      "executing one_batch...\n",
      "parameter update iteration number  7 batch_number  0  learn.stop =  False\n",
      "executing one_batch...\n",
      "parameter update iteration number  8 batch_number  0  learn.stop =  False\n",
      "executing one_batch...\n",
      "parameter update iteration number  9 batch_number  0  learn.stop =  False\n",
      "executing one_batch...\n",
      "parameter update iteration number  10 batch_number  0  learn.stop =  True\n",
      "begin_validate state  True\n",
      "self.learn.stop  False\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n",
      "executing one_batch...\n",
      "exiting from one_batch due to after_loss...\n"
     ]
    }
   ],
   "source": [
    "# run a training loop with TestCallback()\n",
    "# The input is a CallbackHandler \n",
    "# Q: Why are there only 10 parameter update iterations? \n",
    "#    There should be 10 iterations for each batch\n",
    "# A: Once n_iter reaches 10, the learn.stop flag is set:\n",
    "#    the program exits the training loop and processes the validation data, since begin_validate() is True\n",
    "#    so with this call, fit() processes only a single batch\n",
    "fit(learn, callback=CallbackHandler([TestCallback()]),n_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is roughly how fastai does it now (except that the handler can also change and return `xb`, `yb`, and `loss`). But let's see if we can make things simpler and more flexible, so that a single class has access to everything and can change anything at any time. The fact that we're passing the `callback` list to so many functions is a strong hint they should all be in the same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Why is learn.stop still `False`? The training loop set it to `True` before exiting.\n",
    "### A: but then the validation loop set it back to `False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=5811)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Refactor the Callback() class\n",
    "Callback() now becomes a container for a callback function, which can be passed in via the set_runner() method.\n",
    "\n",
    "Add a `name` property, `_order` and `run` attributes, and a `__getattr__` method to get the callback name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import re\n",
    "\n",
    "# helper function uses regular expressions to transform a CamelCase callback name to snake_case\n",
    "_camel_re1 = re.compile('(.)([A-Z][a-z]+)')\n",
    "_camel_re2 = re.compile('([a-z0-9])([A-Z])')\n",
    "def camel2snake(name):\n",
    "    s1 = re.sub(_camel_re1, r'\\1_\\2', name)\n",
    "    return re.sub(_camel_re2, r'\\1_\\2', s1).lower()\n",
    "\n",
    "# refactored Callback() class\n",
    "class Callback():\n",
    "        \n",
    "    # initialize _order to zero. \n",
    "    _order=0\n",
    "    \n",
    "    # set_runner() method takes a callback as an input\n",
    "    #     note that initially self.run is unset -- there is no default value \n",
    "    def set_runner(self, run): \n",
    "        self.run=run\n",
    "    \n",
    "    def __getattr__(self, callback_name): \n",
    "        return getattr(self.run, callback_name)\n",
    "    \n",
    "    # set the callback name property\n",
    "    #     if the callback doesn't have a name, set the callback name property to 'callback'\n",
    "    @property\n",
    "    def name(self):\n",
    "        name = re.sub(r'Callback$', '', self.__class__.__name__)\n",
    "        return camel2snake(name or 'callback')\n",
    "        # note: the above line is equivalent to the following block\n",
    "        '''\n",
    "        try:\n",
    "            return camel2snake(name)\n",
    "        except:\n",
    "            return 'callback'\n",
    "        '''\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Callback() works now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1.run is undefined\n"
     ]
    }
   ],
   "source": [
    "# instantiate a Callback() object\n",
    "c1 = Callback()\n",
    "try:\n",
    "    print(c1.run)\n",
    "except:\n",
    "    print('c1.run is undefined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1.run is now  <__main__.TestCallback object at 0x0000027228BEA048>\n"
     ]
    }
   ],
   "source": [
    "# pass a callback function to the Callback() object\n",
    "c1.set_runner(TestCallback())\n",
    "print('c1.run is now ',c1.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method TestCallback.after_step of <__main__.TestCallback object at 0x0000027228BEA048>>\n"
     ]
    }
   ],
   "source": [
    "# check the getattr metod\n",
    "f = getattr(c1, 'after_step', None)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method TestCallback.after_step of <__main__.TestCallback object at 0x0000027228BEA048>>\n"
     ]
    }
   ],
   "source": [
    "# an equivalent way to check the getattr method\n",
    "g = Callback.__getattr__(c1,'after_step')\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Transform a CamelCase string to snake_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CamelCase string is  IngeniousNewAmazingTrick ; snake_case is  ingenious_new_amazing_trick\n"
     ]
    }
   ],
   "source": [
    "# construct a 'snake case' callback name given a 'camel case' callback name\n",
    "CamelCaseString = 'IngeniousNewAmazingTrick'\n",
    "print('CamelCase string is ',CamelCaseString,'; snake_case is ',camel2snake(CamelCaseString))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor the TestCallback() class \n",
    "\n",
    "after_step checks whether the number of iterations has reached the maximum allowed value, and if so returns `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(Callback):\n",
    "    def after_step(self):\n",
    "        \n",
    "        print('parameter update iteration number ',self.n_iter,'batch_number ',self.n_batch)\n",
    "\n",
    "        if self.train_eval.n_iter >= max_iter: \n",
    "            return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a TrainEvalCallback Class\n",
    "This is just a collection of methods to handle training and validation and to maintain count of iterations and of fraction of an epoch completed after each batch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TrainEvalCallback(Callback):\n",
    "    \n",
    "    # initialize the epoch, batch, and iteration counters\n",
    "    def begin_fit(self):\n",
    "        # n_epoch_float keeps track of fractional number of elapsed epochs\n",
    "        self.run.n_epoch_float = 0.\n",
    "        self.run.n_batch = 0\n",
    "        self.run.n_iter = 0\n",
    "    \n",
    "    # if we are in the training phase, update the epoch and batch counters\n",
    "    def after_batch(self):\n",
    "        if not self.in_train: \n",
    "            return\n",
    "        # each batch represents a fraction of an epoch\n",
    "        self.run.n_epoch_float += 1./self.n_batches\n",
    "        self.run.n_batch   += 1\n",
    "    \n",
    "    # execute the training phase\n",
    "    def begin_epoch(self):\n",
    "        self.run.n_epoch_float=self.n_epoch_float\n",
    "        self.model.train()\n",
    "        self.run.in_train=True\n",
    "    \n",
    "    # execute the prediction phase\n",
    "    def begin_validate(self):\n",
    "        self.model.eval()\n",
    "        self.run.in_train=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Contructing the callback name\n",
    "By convention, a CamelCase callback name contains a suffix, 'Callback'.\n",
    "\n",
    "We remove the suffix, then transform to snake_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainEvalCallback().name is  train_eval\n"
     ]
    }
   ],
   "source": [
    "# remove the 'Callback' suffix, then transform to snake_case\n",
    "print('TrainEvalCallback().name is ',TrainEvalCallback().name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. The Runner Class, a hackable training/validation module\n",
    "to be implemented in fastai v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import *\n",
    "\n",
    "# helper function to convert any input into a list\n",
    "def listify(o):\n",
    "    if o is None: return []\n",
    "    if isinstance(o, list): return o\n",
    "    if isinstance(o, str): return [o]\n",
    "    if isinstance(o, Iterable): return list(o)\n",
    "    return [o]\n",
    "\n",
    "\n",
    "class Runner():\n",
    "    # initialize by setting the stop Flag to False, and constructing a list of callbacks from the inputs\n",
    "    def __init__(self, callbacks=None, callback_funcs=None):\n",
    "        # inputs are two lists: callbacks and callback_funcs\n",
    "        # Q: it's not clear why we need two lists rather than one\n",
    "        # create a list of callbacks from the input callbacks\n",
    "        callbacks = listify(callbacks)\n",
    "        # associate each callback_func() to its snake case callback name, then append it to the callbacks list\n",
    "        for callback_func in listify(callback_funcs):\n",
    "            callback = callback_func()\n",
    "            setattr(self, callback.name, callback)\n",
    "            callbacks.append(callback)\n",
    "        # set the stopping flag to `False` and append TrainEvalCallback() to the callbacks list\n",
    "        self.stop,self.callbacks = False,[TrainEvalCallback()]+callbacks\n",
    "\n",
    "    # get the properties of the Learner object\n",
    "    @property\n",
    "    def opt(self):       return self.learn.opt\n",
    "    @property\n",
    "    def model(self):     return self.learn.model\n",
    "    @property\n",
    "    def loss_func(self): return self.learn.loss_func\n",
    "    @property\n",
    "    def data(self):      return self.learn.data\n",
    "\n",
    "    # method to process a single batch\n",
    "    def one_batch(self, xb, yb):\n",
    "        self.xb,self.yb = xb,yb\n",
    "        if self('begin_batch'): \n",
    "            return\n",
    "        # run the model\n",
    "        self.pred = self.model(self.xb)\n",
    "        if self('after_pred'): \n",
    "            return\n",
    "        # compute the loss function\n",
    "        self.loss = self.loss_func(self.pred, self.yb)\n",
    "        if self('after_loss') or not self.in_train: \n",
    "            return\n",
    "        # do backpropagation\n",
    "        self.loss.backward()\n",
    "        if self('after_backward'): \n",
    "            return\n",
    "        # update parameters\n",
    "        self.opt.step()\n",
    "        if self('after_step'): \n",
    "            return\n",
    "        # zero the gradients to prepare for the next batch\n",
    "        self.opt.zero_grad()\n",
    "        \n",
    "    # method to process all batches\n",
    "    def all_batches(self, dataloader):\n",
    "        # total number of batches in an epoch\n",
    "        self.n_batches = len(dataloader)\n",
    "        # self.n_epoch_float = 0.\n",
    "        for xb,yb in dataloader:\n",
    "            # break if run.stop flag has been set\n",
    "            if self.stop: \n",
    "                break\n",
    "            # process the next batch, then run the `after_batch` callback\n",
    "            self.one_batch(xb, yb)\n",
    "            self('after_batch')\n",
    "        # set the run.stop flag to `False`    \n",
    "        self.stop=False\n",
    "\n",
    "    # method to process training or validation data\n",
    "    def fit(self, learn, n_epochs):\n",
    "        self.n_epochs,self.learn = n_epochs,learn\n",
    "\n",
    "        try:\n",
    "            # loop over all callbacks in list and set_runner for each one\n",
    "            for callback in self.callbacks: \n",
    "                callback.set_runner(self)\n",
    "            if self('begin_fit'): \n",
    "                return\n",
    "            for epoch_number in range(n_epochs):\n",
    "                self.epoch_number = epoch_number\n",
    "                \n",
    "                # training phase\n",
    "                if not self('begin_epoch'): \n",
    "                    self.all_batches(self.data.train_dl)\n",
    "                \n",
    "                # validation phase\n",
    "                with torch.no_grad(): \n",
    "                    if not self('begin_validate'): \n",
    "                        self.all_batches(self.data.valid_dl)\n",
    "                # break if `after_epoch` state is `True`\n",
    "                if self('after_epoch'): \n",
    "                    break\n",
    "            \n",
    "        finally:\n",
    "            # set the `after_fit` state to `True`\n",
    "            self('after_fit')\n",
    "            # erase the Learner object\n",
    "            self.learn = None\n",
    "\n",
    "    def __call__(self, callback_name):\n",
    "        # __call__ allows an instance of this class to be called as a function\n",
    "        # loop through the callback list, return True if the requested callback callback_name is present, \n",
    "        #     otherwise return False\n",
    "        for callback in sorted(self.callbacks, key=lambda x: x._order):\n",
    "            # check this callback name, and return True if it is the requested callback\n",
    "            # get the callback associated with callback_name, otherwise return None\n",
    "            f = getattr(callback, callback_name, None)\n",
    "            if f and f(): # guarantees that the callback is present and is a function\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AvgStatsCallback computes loss and metrics, such as accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AvgStats():\n",
    "    def __init__(self, metrics, in_train): \n",
    "        self.metrics,self.in_train = listify(metrics),in_train\n",
    "    \n",
    "    # initialize total_loss and count to zero, and total_metrics to zeros for each metric\n",
    "    def reset(self):\n",
    "        # count keeps track of total samples processed\n",
    "        self.total_loss,self.count = 0.,0\n",
    "        self.total_metrics = [0.] * len(self.metrics)\n",
    "        \n",
    "    # combine loss and metrics\n",
    "    @property\n",
    "    def all_stats(self):\n",
    "        # all_stats is a list containing loss and all metrics\n",
    "        # Q: why does total_loss have to be extracted with .item()\n",
    "        return [self.total_loss.item()] + self.total_metrics\n",
    "    \n",
    "    # compute avg loss and metrics per sample\n",
    "    @property\n",
    "    def avg_stats(self):\n",
    "        # each stat is averaged over the number of samples\n",
    "        return [o/self.count for o in self.all_stats]\n",
    "    \n",
    "    # compute and display stats\n",
    "    def __repr__(self):\n",
    "        if not self.count: \n",
    "            return \"\"\n",
    "        return f\"{'train' if self.in_train else 'valid'}: {self.avg_stats}\"\n",
    "\n",
    "    def accumulate(self, run):\n",
    "        # get the number of samples in this batch\n",
    "        n_samples_in_batch = run.xb.shape[0]\n",
    "        # weight the loss function for the batch by the number of samples in the batch\n",
    "        self.total_loss += run.loss * n_samples_in_batch\n",
    "        # accumulate count of samples processed\n",
    "        self.count += n_samples_in_batch\n",
    "        # accumulate the metrics, weighting each by number of samples in the batch\n",
    "        for i,metric in enumerate(self.metrics):\n",
    "            self.total_metrics[i] += metric(run.pred, run.yb) * n_samples_in_batch\n",
    "\n",
    "class AvgStatsCallback(Callback):\n",
    "    def __init__(self, metrics):\n",
    "        self.train_stats,self.valid_stats = AvgStats(metrics,in_train=True),AvgStats(metrics,in_train=False)\n",
    "        \n",
    "    # initialize train_stats and valid_stats at the start of an epoch\n",
    "    def begin_epoch(self):\n",
    "        self.train_stats.reset()\n",
    "        self.valid_stats.reset()\n",
    "        \n",
    "    # compute and accumulate stats after the loss function has been evaluated\n",
    "    def after_loss(self):\n",
    "        stats = self.train_stats if self.in_train else self.valid_stats\n",
    "        with torch.no_grad(): \n",
    "            stats.accumulate(self.run)\n",
    "    # print stats after the epoch has been processed\n",
    "    def after_epoch(self):\n",
    "        print(self.train_stats)\n",
    "        print(self.valid_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Validation Method 1: \n",
    "### Use the Runner() class with the `callbacks` input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate an AvgStatsCallback with the accuracy metric\n",
    "stats = AvgStatsCallback([accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a Runner object using the callbacks input\n",
    "run = Runner(callbacks=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a learner object with data, loss_func, opt and model\n",
    "learn = Learner(*get_model(data), loss_func, data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.3064101953125, tensor(0.9056)]\n",
      "valid: [0.3826717041015625, tensor(0.8782)]\n",
      "train: [0.142082958984375, tensor(0.9569)]\n",
      "valid: [0.2425769775390625, tensor(0.9223)]\n"
     ]
    }
   ],
   "source": [
    "# run a training loop\n",
    "run.fit(learn, n_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2425769775390625, tensor(0.9223))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute stats, which got modified by the call to run.fit\n",
    "loss,acc = stats.valid_stats.avg_stats\n",
    "assert acc>0.9\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Validation Method #2: \n",
    "###  Use the Runner() class with the `callback_funcs()` input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contruct a callback_func that does the same job as stats, above\n",
    "stats_func = partial(AvgStatsCallback,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a Runner object using the callback_funcs() input\n",
    "run = Runner(callback_funcs=stats_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a Learner object with data, loss_func, opt and model\n",
    "learn = Learner(*get_model(data), loss_func, data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.3240140625, tensor(0.8977)]\n",
      "valid: [0.2048943115234375, tensor(0.9350)]\n",
      "train: [0.142941611328125, tensor(0.9555)]\n",
      "valid: [0.136198046875, tensor(0.9598)]\n"
     ]
    }
   ],
   "source": [
    "# run a training/validation loop\n",
    "run.fit(learn, n_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.136198046875, tensor(0.9598)]\n",
      "valid: [0.136198046875, tensor(0.9598)]\n"
     ]
    }
   ],
   "source": [
    "# get statistics\n",
    "print(run.avg_stats.valid_stats.avg_stats)\n",
    "print(run.avg_stats.valid_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 04_callbacks_jcat.ipynb to exp\\nb_04.py\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py 04_callbacks_jcat.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
