{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all code from previous notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_03 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the MNIST training and validation data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=4799)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()\n",
    "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
    "nh,bs = 50,64\n",
    "c = y_train.max().item()+1\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 784])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# data set properties x and y come from Dataset\n",
    "print(valid_ds.x.shape)\n",
    "print(valid_ds.y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Improving the fit() function\n",
    "### Factor the connected pieces of information (model, optimizer, loss function and data) from the `fit()` argument list into a `Learner Class object`\n",
    "\n",
    "`fit(n_epochs, model, loss_func, opt, train_dl, valid_dl)`\n",
    "\n",
    "Let's modify the call to `fit()` to look like this:\n",
    "\n",
    "`fit(n_epochs, learner)`\n",
    "\n",
    "Here, `learner` is a `Learner` Class object, that we will define as a container for `model`, `loss_func`, `opt`, `train_dl`, `valid_dl` to be passed into `fit()`\n",
    "\n",
    "This will allow us to tweak what's happening inside the training loop in other places of the code. Because the `Learner` Class object will be mutable, changing any of its attributes elsewhere will modify our training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=5363)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The DataBunch class\n",
    "For convenience we define a `DataBunch()` class, as a container for the DataLoader() objects and optionally n_out, the number of output channels.\n",
    "DataBunch() takes inputs train_dl(), valid_dl(), and optionally n_out.\n",
    "It has properties train_ds(), valid_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataBunch():\n",
    "    def __init__(self, train_dl, valid_dl, n_out=None):\n",
    "        self.train_dl,self.valid_dl,self.n_out = train_dl,valid_dl,n_out\n",
    "    \n",
    "    # add train_ds() as an attribute\n",
    "    @property\n",
    "    def train_ds(self): return self.train_dl.dataset\n",
    "     \n",
    "        \n",
    "    # add valid_ds() as an attribute\n",
    "    @property\n",
    "    def valid_ds(self): return self.valid_dl.dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Learner Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# instantiates the model and the optimizer, given the data and parameters\n",
    "def get_model(data, learning_rate=0.5, n_hidden = 50):\n",
    "    n_columns = data.train_ds.x.shape[1]\n",
    "    n_out = data.n_out\n",
    "    model = nn.Sequential(nn.Linear(n_columns,n_hidden), nn.ReLU(), nn.Linear(n_hidden,n_out))\n",
    "    # why can we access the optimizer from within this function?\n",
    "    return model, optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# the Learner() class is a container for the model, optimization, loss function and data \n",
    "class Learner():\n",
    "    def __init__(self, model, opt, loss_func, data):\n",
    "        self.model,self.opt,self.loss_func,self.data = model,opt,loss_func,data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor the fit() function according to plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refactor the fit() function according to our plan\n",
    "#     Note the order of the inputs has been switched in order to allow n_epochs to be a keyword argument\n",
    "def fit(learn,n_epochs):\n",
    "    \n",
    "    # n_epochs is a keyword argument\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # training phase\n",
    "        learn.model.train()\n",
    "        for xb,yb in learn.data.train_dl:\n",
    "            pred = learn.model(xb)\n",
    "            loss = learn.loss_func(pred, yb)\n",
    "            loss.backward()\n",
    "            learn.opt.step()\n",
    "            learn.opt.zero_grad()\n",
    "\n",
    "        # prediction phase\n",
    "        # tells pytorch that we are in eval phase, so no dropout, batchnorm, etc.\n",
    "        learn.model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_loss,tot_acc = 0.,0.\n",
    "            for xb,yb in learn.data.valid_dl:\n",
    "                pred = learn.model(xb)\n",
    "                tot_loss += learn.loss_func(pred, yb)\n",
    "                tot_acc  += accuracy(pred,yb)\n",
    "        \n",
    "        # compute average loss and accuracy\n",
    "        n_valid = len(learn.data.valid_dl)\n",
    "        avg_loss, avg_acc = tot_loss/n_valid, tot_acc/n_valid\n",
    "        print(epoch, avg_loss ,avg_acc )\n",
    "        \n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for minibatch training package up the data into a DataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 784])\n",
      "torch.Size([50000])\n"
     ]
    }
   ],
   "source": [
    "# package up the data in a DataBunch object\n",
    "# the * forces you to generate and process the entire sample\n",
    "batch_size = 64\n",
    "n_out = 10\n",
    "data = DataBunch(*get_dls(train_ds, valid_ds, batch_size=batch_size), n_out=n_out)\n",
    "\n",
    "# data also has properties x and y, inherited from train_ds\n",
    "print(data.train_dl.dataset.x.shape)\n",
    "print(data.train_dl.dataset.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a Learner object\n",
    "learn = Learner(*get_model(data), loss_func, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# check module list outputs\n",
    "print(learn.model.train())\n",
    "print(learn.model.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate a minibatch training loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.4549) tensor(0.8686)\n"
     ]
    }
   ],
   "source": [
    "# instantiate a minibatch training loop and start training!\n",
    "loss,acc = fit(learn, n_epochs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Adding callbacks \n",
    "Callbacks are functions that can be set to initiate desired sequences of actions at various stages in the minibatch training process. They will allow us to simplify the training loop, and provide added flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our training loop (without validation) from the previous notebook, with the inner loop contents factored out:\n",
    "\n",
    "```python\n",
    "def one_batch(xb,yb):\n",
    "    pred = model(xb)\n",
    "    loss = loss_func(pred, yb)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "def fit():\n",
    "    for epoch in range(n_epochs):\n",
    "        for b in train_dl: one_batch(*b)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=5628)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CallBack() Class\n",
    "\n",
    "Is a container for a set of nine basic callback methods.\n",
    "\n",
    "Each method is associated with a well-defined stage in the training process, and returns `True` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback():\n",
    "    def begin_fit(self, learn):\n",
    "        self.learn = learn\n",
    "        return True\n",
    "    def after_fit(self):\n",
    "        return True\n",
    "    def begin_epoch(self, epoch):\n",
    "        self.epoch=epoch\n",
    "        return True\n",
    "    def begin_validate(self):\n",
    "        return True\n",
    "    def after_epoch(self): \n",
    "        return True\n",
    "    def begin_batch(self, xb, yb):\n",
    "        self.xb,self.yb = xb,yb\n",
    "        return True\n",
    "    def after_loss(self, loss):\n",
    "        self.loss = loss\n",
    "        return True\n",
    "    def after_backward(self):\n",
    "        return True\n",
    "    def after_step(self):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CallbackHandler Class\n",
    "\n",
    "is a container for a collection of methods comprised of\n",
    "\n",
    "    (1) a \"wrapper\" for each method in the Callback() class \n",
    "\n",
    "    (2) a do_stop() method that can set the learn.stop flag\n",
    "    \n",
    "takes a list of Callback() objects  as input\n",
    "\n",
    "each \"wrapper\" modifies the behavior of its associated callback, and returns a state flag, as follows:\n",
    "    - initialize the state flag\n",
    "    - optionally set some object properties and/or run some methods\n",
    "    - for each Callback() object in the input list:\n",
    "      check whether the callback is among its methods \n",
    "         if so, execute the callback, and\n",
    "            if the callback returns True, set the state flag to its initialized value\n",
    "            if the callback returns False, set the state flag to False\n",
    "         if not, set the state flag to False\n",
    "    - return the state flag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallbackHandler():\n",
    "    def __init__(self,callbacks=None):\n",
    "        self.callbacks = callbacks if callbacks else []\n",
    "\n",
    "    def begin_fit(self, learn):\n",
    "        self.learn,self.in_train = learn,True\n",
    "        learn.stop = False\n",
    "        state = True\n",
    "        for callback in self.callbacks: \n",
    "            state = state and callback.begin_fit(learn)\n",
    "        return state\n",
    "\n",
    "    def after_fit(self):\n",
    "        state = not self.in_train\n",
    "        for callback in self.callbacks: \n",
    "            state = state and callback.after_fit()\n",
    "        return state\n",
    "    \n",
    "    def begin_epoch(self, epoch):\n",
    "        # the next line trains the model\n",
    "        self.learn.model.train()\n",
    "        self.in_train=True\n",
    "        state = True\n",
    "        for callback in self.callbacks: \n",
    "            state = state and callback.begin_epoch(epoch)\n",
    "        return state\n",
    "\n",
    "    def begin_validate(self):\n",
    "        # what does the next line do?\n",
    "        self.learn.model.eval()\n",
    "        self.in_train=False\n",
    "        state = True\n",
    "        for callback in self.callbacks: \n",
    "            state = state and callback.begin_validate()\n",
    "        return state\n",
    "\n",
    "    def after_epoch(self):\n",
    "        state = True\n",
    "        for callback in self.callbacks: \n",
    "            state = state and callback.after_epoch()\n",
    "        return state\n",
    "    \n",
    "    def begin_batch(self, xb, yb):\n",
    "        state = True\n",
    "        for callback in self.callbacks:\n",
    "            state = state and callback.begin_batch(xb, yb)\n",
    "        return state\n",
    "\n",
    "    def after_loss(self, loss):\n",
    "        state = self.in_train\n",
    "        for callback in self.callbacks: \n",
    "            state = state and callback.after_loss(loss)\n",
    "        return state\n",
    "\n",
    "    def after_backward(self):\n",
    "        state = True\n",
    "        for callback in self.callbacks: \n",
    "            state = state and callback.after_backward()\n",
    "        return state\n",
    "\n",
    "    def after_step(self):\n",
    "        state = True\n",
    "        for callback in self.callbacks: \n",
    "            state = state and callback.after_step()\n",
    "        return state\n",
    "    \n",
    "    def do_stop(self):\n",
    "        try:     \n",
    "            return self.learn.stop\n",
    "        finally: \n",
    "            self.learn.stop = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A TestCallback Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(Callback):\n",
    "    \n",
    "    # Q: does the begin_fit() callback below inherit from \n",
    "    #     the Callback() class, or \n",
    "    #     from the CallbackHandler() class? \n",
    "    # A: I think from the Callback() class\n",
    "\n",
    "    # modify the begin_fit() callback by adding an iteration counter\n",
    "    def begin_fit(self,learn):\n",
    "        # calls begin_fit() method from the Callback class\n",
    "        super().begin_fit(learn)\n",
    "        self.n_iters = 0\n",
    "        max_iter = 10\n",
    "        self.max_iter = max_iter\n",
    "        # self.n_epochs_float = 0.\n",
    "        return True\n",
    "    \n",
    "    # modify the afer_step() callback to increment the iteration counter, print the current iteration number,\n",
    "    #   and to set the learn.stop flag to True after max_iter iterations\n",
    "    # Q: why doesn't after_step() inherit from its previous definition, as we did with begin_fit()?\n",
    "    # A: because after_step() does nothing but return True\n",
    "    def after_step(self):\n",
    "        self.n_iters += 1\n",
    "        print(self.n_iters)\n",
    "        if self.n_iters>=self.max_iter: \n",
    "            self.learn.stop = True\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor the training loop using callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process a single batch, with an input list of callbacks\n",
    "def one_batch(xb, yb, callback):\n",
    "    \n",
    "    # run the model and computer the loss function for the current batch\n",
    "    if not callback.begin_batch(xb,yb): \n",
    "        return\n",
    "    loss = callback.learn.loss_func(callback.learn.model(xb), yb)\n",
    "    \n",
    "    # do backpropagation for the current batch\n",
    "    if not callback.after_loss(loss): \n",
    "        return\n",
    "    loss.backward()\n",
    "    \n",
    "    # update the parameters for the current batch\n",
    "    if callback.after_backward(): \n",
    "        callback.learn.opt.step()\n",
    "        \n",
    "    # zero the gradients to prepare for the next batch\n",
    "    if callback.after_step(): \n",
    "        callback.learn.opt.zero_grad()\n",
    "\n",
    "# process the entire dataset, with an input list of callbacks\n",
    "#   (i.e. loop through all the batches)\n",
    "def all_batches(dataloader, callback):\n",
    "    for xb,yb in dataloader:\n",
    "        \n",
    "        # process a batch, then check whether to stop or to process the next batch\n",
    "        one_batch(xb, yb, callback)\n",
    "        if callback.do_stop(): \n",
    "            return\n",
    "\n",
    "# training loop with an input callbacks\n",
    "def fit(learn, callback, n_epochs):\n",
    "    \n",
    "    # check whether or not to start the training loop\n",
    "    if not callback.begin_fit(learn): \n",
    "        return\n",
    "    \n",
    "    # loop over the specified number of epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # check whether or not to process the next epoch\n",
    "        if not callback.begin_epoch(epoch): \n",
    "            continue # jumps to next epoch\n",
    "        all_batches(learn.data.train_dl, callback)\n",
    "        \n",
    "        # check whether or not to process the validation set\n",
    "        if callback.begin_validate():\n",
    "            with torch.no_grad(): \n",
    "                all_batches(learn.data.valid_dl, callback)\n",
    "        \n",
    "        # check whether or not to break after the current epoch has been processed\n",
    "        if callback.do_stop() or not callback.after_epoch(): \n",
    "            break\n",
    "            \n",
    "    # set the callback state to indicate that fit() has been run\n",
    "    callback.after_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# run a training loop with TestCallback()\n",
    "# The input is a CallbackHandler \n",
    "fit(learn, callback=CallbackHandler([TestCallback()]),n_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is roughly how fastai does it now (except that the handler can also change and return `xb`, `yb`, and `loss`). But let's see if we can make things simpler and more flexible, so that a single class has access to everything and can change anything at any time. The fact that we're passing the `callback` list to so many functions is a strong hint they should all be in the same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is learn.stop still `False`? The training loop should have set it to `True` before being interrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=5811)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor the Callback() class\n",
    "Callback() now becomes a container for a callback function, which can be passed in via the set_runner() method.\n",
    "Add a `name` property, `_order` and `run` attributes, and a `__getattr__` method\n",
    "\n",
    "Note: I'm confused about what `__getattr__` does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import re\n",
    "\n",
    "# use regular expressions to construct a 'snake case' callback name for each 'camel case' callback name\n",
    "_camel_re1 = re.compile('(.)([A-Z][a-z]+)')\n",
    "_camel_re2 = re.compile('([a-z0-9])([A-Z])')\n",
    "def camel2snake(name):\n",
    "    s1 = re.sub(_camel_re1, r'\\1_\\2', name)\n",
    "    return re.sub(_camel_re2, r'\\1_\\2', s1).lower()\n",
    "\n",
    "# refactored Callback() class\n",
    "class Callback():\n",
    "        \n",
    "    # initialize _order to zero. \n",
    "    _order=0\n",
    "    \n",
    "    # set_runner() method serves to replace all the basic callback methods\n",
    "    #     note that initially self.run is unset -- there is no default value \n",
    "    def set_runner(self, run): \n",
    "        self.run=run\n",
    "    \n",
    "    def __getattr__(self, cb): \n",
    "        return getattr(self.run, cb)\n",
    "    @property\n",
    "    def name(self):\n",
    "        name = re.sub(r'Callback$', '', self.__class__.__name__)\n",
    "        # if name does not exist, set the name to 'callback'\n",
    "        return camel2snake(name or 'callback')\n",
    "        # the above line is equivalent to the following block\n",
    "        '''\n",
    "        try:\n",
    "            return camel2snake(name)\n",
    "        except:\n",
    "            return 'callback'\n",
    "        '''\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: CamelCase vs. snake_case callback names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camel case name is  IngeniousNewAmazingCallback ; snake case name is  ingenious_new_amazing_callback\n"
     ]
    }
   ],
   "source": [
    "# construct a 'snake case' callback name given a 'camel case' callback name\n",
    "callback_name = 'IngeniousNewAmazingCallback'\n",
    "print('camel case name is ',callback_name,'; snake case name is ',camel2snake(callback_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Callback() works now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1.run is undefined\n"
     ]
    }
   ],
   "source": [
    "# instantiate a Callback() object\n",
    "c1 = Callback()\n",
    "try:\n",
    "    print(c1.run)\n",
    "except:\n",
    "    print('c1.run is undefined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1.run is now  <__main__.TestCallback object at 0x000002950146E6D8>\n"
     ]
    }
   ],
   "source": [
    "# pass a callback function to the Callback() object\n",
    "c1.set_runner(TestCallback())\n",
    "print('c1.run is now ',c1.run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor the TestCallback() class \n",
    "\n",
    "This version just tests whether the number of iterations has reached the maximum allowed value after each parameter update step and if so returns `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(Callback):\n",
    "    def after_step(self):\n",
    "        if self.train_eval.n_iters>=max_iter: \n",
    "            return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a TrainEvalCallback Class\n",
    "with methods to handle training and validation and to maintain count of iterations and of fraction of an epoch completed after each batch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TrainEvalCallback(Callback):\n",
    "    \n",
    "    # initialize the epoch and iteration counters\n",
    "    def begin_fit(self):\n",
    "        # n_epochs_float keeps track of where we are in the current epoch, need not be integer\n",
    "        #     in original code, this variable was named n_epochs, but there is another variable with than name\n",
    "        #     so it is preferable to give it a more apporpriate and descriptive name.\n",
    "        self.run.n_epochs_float=0.\n",
    "        self.run.n_iter=0\n",
    "    \n",
    "    # if we are in the training phase, increment the epoch and iteration counters\n",
    "    def after_batch(self):\n",
    "        if not self.in_train: \n",
    "            return\n",
    "        # each training iteration represents a fraction of an epoch\n",
    "        #      n_iters comes from TestCallback(), and is an attribute of begin_fit()\n",
    "        self.run.n_epochs_float += 1./self.n_iters\n",
    "        self.run.n_iter   += 1\n",
    "    \n",
    "    # execute the training phase\n",
    "    def begin_epoch(self):\n",
    "        self.run.n_epochs_float=self.n_epochs_float\n",
    "        self.model.train()\n",
    "        self.run.in_train=True\n",
    "    \n",
    "    # execute prediction phase\n",
    "    def begin_validate(self):\n",
    "        self.model.eval()\n",
    "        self.run.in_train=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contructing the callback name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainEvalCallback().name is  train_eval\n"
     ]
    }
   ],
   "source": [
    "# trim out the substring 'Callback' then return the snake case name\n",
    "print('TrainEvalCallback().name is ',TrainEvalCallback().name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to convert any input to a list (for export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import *\n",
    "\n",
    "# function to convert any input into a list\n",
    "def listify(o):\n",
    "    if o is None: return []\n",
    "    if isinstance(o, list): return o\n",
    "    if isinstance(o, str): return [o]\n",
    "    if isinstance(o, Iterable): return list(o)\n",
    "    return [o]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Runner Class -- to be implemented in fastai v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Runner():\n",
    "    def __init__(self, callbacks=None, callback_funcs=None):\n",
    "        # create a list of callbacks from the input callbacks\n",
    "        callbacks = listify(callbacks)\n",
    "        # append to the callbacks list from the input list of callback_funcs\n",
    "        for callback_func in listify(callback_funcs):\n",
    "            callback = callback_func()\n",
    "            setattr(self, callback.name, callback)\n",
    "            callbacks.append(callback)\n",
    "        # set the stopping flag to `False` and append TrainEvalCallback() to the callbacks list\n",
    "        self.stop,self.callbacks = False,[TrainEvalCallback()]+callbacks\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def opt(self):       return self.learn.opt\n",
    "    @property\n",
    "    def model(self):     return self.learn.model\n",
    "    @property\n",
    "    def loss_func(self): return self.learn.loss_func\n",
    "    @property\n",
    "    def data(self):      return self.learn.data\n",
    "\n",
    "    def one_batch(self, xb, yb):\n",
    "        self.xb,self.yb = xb,yb\n",
    "        if self('begin_batch'): \n",
    "            return\n",
    "        # run the model\n",
    "        self.pred = self.model(self.xb)\n",
    "        if self('after_pred'): \n",
    "            return\n",
    "        # compute the loss function\n",
    "        self.loss = self.loss_func(self.pred, self.yb)\n",
    "        if self('after_loss') or not self.in_train: \n",
    "            return\n",
    "        # do backpropagation\n",
    "        self.loss.backward()\n",
    "        if self('after_backward'): \n",
    "            return\n",
    "        # update parameters\n",
    "        self.opt.step()\n",
    "        if self('after_step'): \n",
    "            return\n",
    "        # zero the gradients to prepare for the next batch\n",
    "        self.opt.zero_grad()\n",
    "        \n",
    "    def all_batches(self, dataloader):\n",
    "        self.n_iters = len(dataloader)\n",
    "        self.n_epochs_float = 0.\n",
    "        for xb,yb in dataloader:\n",
    "            # break if stopping flag has been set\n",
    "            if self.stop: \n",
    "                break\n",
    "            # process the next batch and set the `after_batch` flag\n",
    "            self.one_batch(xb, yb)\n",
    "            self('after_batch')\n",
    "        # set the stopping flag to `False`    \n",
    "        self.stop=False\n",
    "\n",
    "    def fit(self, learn, n_epochs):\n",
    "        self.n_epochs,self.learn = n_epochs,learn\n",
    "\n",
    "        try:\n",
    "            for callback in self.callbacks: \n",
    "                callback.set_runner(self)\n",
    "            if self('begin_fit'): \n",
    "                return\n",
    "            for epoch in range(n_epochs):\n",
    "                self.epoch = epoch\n",
    "                \n",
    "                # training phase\n",
    "                if not self('begin_epoch'): \n",
    "                    self.all_batches(self.data.train_dl)\n",
    "                \n",
    "                # validation phase\n",
    "                with torch.no_grad(): \n",
    "                    if not self('begin_validate'): \n",
    "                        self.all_batches(self.data.valid_dl)\n",
    "                # break if `after_epoch` state is `True`\n",
    "                if self('after_epoch'): \n",
    "                    break\n",
    "            \n",
    "        finally:\n",
    "            # set the `after_fit` state to `True`\n",
    "            self('after_fit')\n",
    "            # erase the learner object\n",
    "            self.learn = None\n",
    "\n",
    "    def __call__(self, cb_name):\n",
    "        # loop through the callback list, return True if the requested callback is present, otherwise return False\n",
    "        for callback in sorted(self.callbacks, key=lambda x: x._order):\n",
    "            # check this callback name, and return True if it is the requested callback\n",
    "            f = getattr(callback, cb_name, None)\n",
    "            if f and f(): \n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AvgStatsCallback computes metrics and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AvgStats():\n",
    "    def __init__(self, metrics, in_train): \n",
    "        self.metrics,self.in_train = listify(metrics),in_train\n",
    "    \n",
    "    # initialize total_loss, count, and total_metrics\n",
    "    def reset(self):\n",
    "        self.total_loss,self.count = 0.,0\n",
    "        self.total_metrics = [0.] * len(self.metrics)\n",
    "        \n",
    "    # combine loss and metrics\n",
    "    @property\n",
    "    def all_stats(self): \n",
    "        return [self.total_loss.item()] + self.total_metrics\n",
    "    \n",
    "    # compute avg loss and metrics\n",
    "    @property\n",
    "    def avg_stats(self): \n",
    "        return [o/self.count for o in self.all_stats]\n",
    "    \n",
    "    # compute and display stats\n",
    "    def __repr__(self):\n",
    "        if not self.count: \n",
    "            return \"\"\n",
    "        return f\"{'train' if self.in_train else 'valid'}: {self.avg_stats}\"\n",
    "\n",
    "    def accumulate(self, run):\n",
    "        # get the number of samples in this batch\n",
    "        n_samples_in_batch = run.xb.shape[0]\n",
    "        # weight the loss function for the batch by the number of samples in the batch\n",
    "        self.total_loss += run.loss * n_samples_in_batch\n",
    "        # accumulate count of samples processed\n",
    "        self.count += n_samples_in_batch\n",
    "        # accumulate the metrics\n",
    "        for i,metric in enumerate(self.metrics):\n",
    "            self.total_metrics[i] += metric(run.pred, run.yb) * n_samples_in_batch\n",
    "\n",
    "class AvgStatsCallback(Callback):\n",
    "    def __init__(self, metrics):\n",
    "        self.train_stats,self.valid_stats = AvgStats(metrics,in_train=True),AvgStats(metrics,in_train=False)\n",
    "        \n",
    "    # initialize train_stats and valid_stats\n",
    "    def begin_epoch(self):\n",
    "        self.train_stats.reset()\n",
    "        self.valid_stats.reset()\n",
    "        \n",
    "    # compute and accumulate stats\n",
    "    def after_loss(self):\n",
    "        stats = self.train_stats if self.in_train else self.valid_stats\n",
    "        with torch.no_grad(): \n",
    "            stats.accumulate(self.run)\n",
    "    # print stats\n",
    "    def after_epoch(self):\n",
    "        print(self.train_stats)\n",
    "        print(self.valid_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a learner object\n",
    "learn = Learner(*get_model(data), loss_func, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set metric to accuracy\n",
    "stats = AvgStatsCallback([accuracy])\n",
    "# instantiate a Runner object\n",
    "run = Runner(callbacks=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.31240044921875, tensor(0.9034)]\n",
      "valid: [0.21252998046875, tensor(0.9320)]\n",
      "train: [0.1383840625, tensor(0.9579)]\n",
      "valid: [0.1312119873046875, tensor(0.9598)]\n"
     ]
    }
   ],
   "source": [
    "# run a training loop\n",
    "run.fit(learn, n_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1312119873046875, tensor(0.9598))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute stats\n",
    "loss,acc = stats.valid_stats.avg_stats\n",
    "assert acc>0.9\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_callback_func = partial(AvgStatsCallback,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = Runner(callback_funcs=acc_callback_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.1027776171875, tensor(0.9687)]\n",
      "valid: [0.111236767578125, tensor(0.9683)]\n"
     ]
    }
   ],
   "source": [
    "run.fit(learn, n_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Jupyter means we can get tab-completion even for dynamic code like this! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.111236767578125, tensor(0.9683)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.avg_stats.valid_stats.avg_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "valid: [0.111236767578125, tensor(0.9683)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.avg_stats.valid_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 04_callbacks_jcat.ipynb to exp\\nb_04.py\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py 04_callbacks_jcat.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
