{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing on the IMDb (Internet Movie Review Database)\n",
    "### The IMDB consists of 50,000 labeled reviews of movies (positive or negative) and 50,000 unlabelled ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_11a import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define a class `TextList` that will directly read text from filenames\n",
    "### `TextList` is a subclass of `ItemList` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_file(fn): \n",
    "    with open(fn, 'r', encoding = 'utf8') as f: return f.read()\n",
    "    \n",
    "class TextList(ItemList):\n",
    "    @classmethod\n",
    "    def from_files(cls, path, extensions='.txt', recurse=True, include=None, **kwargs):\n",
    "        return cls(get_files(path, extensions, recurse=recurse, include=include), path, **kwargs)\n",
    "    \n",
    "    def get(self, i):\n",
    "        if isinstance(i, Path): return read_file(i)\n",
    "        return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import the IMDb Data directly into a `TextList`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 12 video](https://course.fast.ai/videos/?lesson=12&t=4964)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = datasets.untar_data(datasets.URLs.IMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/imdb.vocab'),\n",
       " WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/ld.pkl'),\n",
       " WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/ll_clas.pkl'),\n",
       " WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/README'),\n",
       " WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test'),\n",
       " WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/tmp_clas'),\n",
       " WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/tmp_lm'),\n",
       " WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/train'),\n",
       " WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/unsup')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just in case there are some text log files, we restrict the ones we take to the training, test, and unsupervised folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "il = TextList.from_files(path, include=['train', 'test', 'unsup'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A little Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should expect a total of 100,000 texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(il.items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the first item in the list as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costner's character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutcher's ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = il[0]\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s t r'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = 'str'\n",
    "yy = \" \".join(xx)\n",
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# il has 100,000 text elements\n",
    "len(il)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costner's character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutcher's ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costner'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "# first text element in il (same as txt) has length of 900\n",
    "print(len(il[:100][0]))\n",
    "print(len(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costner's character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutcher's ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before token processing\n",
    "print(len(il[:100][0]))\n",
    "il[:100][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tokenizing using the `spaCy` library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to tokenize the dataset first, which is splitting a sentence in individual tokens. Those tokens are the basic words or punctuation signs with a few tweaks: don't for instance is split between do and n't. We will use a processor for this, in conjunction with the [spaCy library](https://spacy.io/). spaCy describes itself as a purveyor of `Industrial Strength Natural Language Processing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import spacy,html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 12 video](https://course.fast.ai/videos/?lesson=12&t=5070)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Helper functions\n",
    "Before and after tokenization, we will use helper functions to do a bit of processing. These helper functions manipulate text using the powerful syntax of `regular expressions` (sometimes abbreviated `regex`). Python's `re` library implements the language of `regular expressions`. On first encounter, the compact syntax of `re` can be a bit off-putting. It can be annoying, like trying to read a foreign language about which you have no clue. The brain becomes confused at its inability to parse as when reading words of its native language.\n",
    "\n",
    "What each of these helper functions do is made clear by the documentation. So on first pass, think of the `re` operations as black boxes implementing the documentation. For now you needn't worry about the details of regular expressions. \n",
    "\n",
    "At some point, you will eventually need to bite the bullet and understand `regular expressions` to go further in NLP. Here are a few helpful resources once you are ready to learn more:\n",
    "\n",
    "https://scotch.io/tutorials/an-introduction-to-regex-in-python\n",
    "\n",
    "https://www.w3schools.com/python/python_regex.asp\n",
    "\n",
    "http://marvin.cs.uidaho.edu/Handouts/regex.html\n",
    "\n",
    "http://flockhart.virtualave.net/RBIF0100/regexp.html\n",
    "\n",
    "https://jakevdp.github.io/WhirlwindTourOfPython/14-strings-and-regular-expressions.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Pre-proccessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before tokenizeing, we will apply a bit of preprocessing on the texts to clean them up (we saw the one up there had some HTML code). These rules are applied before we split the sentences in tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#special tokens\n",
    "UNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ = \"xxunk xxpad xxbos xxeos xxrep xxwrep xxup xxmaj\".split()\n",
    "\n",
    "def sub_br(t):\n",
    "    \"Replaces the <br /> by \\n\"\n",
    "    re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "    return re_br.sub(\"\\n\", t)\n",
    "\n",
    "def spec_add_spaces(t):\n",
    "    \"Add spaces around / and #\"\n",
    "    return re.sub(r'([/#])', r' \\1 ', t)\n",
    "\n",
    "def rm_useless_spaces(t):\n",
    "    \"Remove multiple spaces\"\n",
    "    return re.sub(' {2,}', ' ', t)\n",
    "\n",
    "def replace_rep(t):\n",
    "    \"Replace repetitions at the character level: cccc -> TK_REP 4 c\"\n",
    "    def _replace_rep(m:Collection[str]) -> str:\n",
    "        c,cc = m.groups()\n",
    "        return f' {TK_REP} {len(cc)+1} {c} '\n",
    "    re_rep = re.compile(r'(\\S)(\\1{3,})')\n",
    "    return re_rep.sub(_replace_rep, t)\n",
    "    \n",
    "def replace_wrep(t):\n",
    "    \"Replace word repetitions: word word word -> TK_WREP 3 word\"\n",
    "    def _replace_wrep(m:Collection[str]) -> str:\n",
    "        c,cc = m.groups()\n",
    "        return f' {TK_WREP} {len(cc.split())+1} {c} '\n",
    "    re_wrep = re.compile(r'(\\b\\w+\\W+)(\\1{3,})')\n",
    "    return re_wrep.sub(_replace_wrep, t)\n",
    "\n",
    "def fixup_text(x):\n",
    "    \"Various messy things we've seen in documents\"\n",
    "    re1 = re.compile(r'  +')\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>',UNK).replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))\n",
    "    \n",
    "default_pre_rules = [fixup_text, replace_rep, replace_wrep, spec_add_spaces, rm_useless_spaces, sub_br]\n",
    "default_spec_tok = [UNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' xxrep 4 c '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_rep('cccc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' xxwrep 5 word  '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_wrep('word word word word word ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Post-proccessing\n",
    "After tokenization we process the tokens to remove capitalization, but adding marker tokens to flag the start and end of the text and to preserve information about where the capitalization was in the original text.\n",
    "\n",
    "`TK_UP` indicates that the next token was originally in all caps\n",
    "\n",
    "`TK_MAJ` indicates that the next token was originally capitalized\n",
    "\n",
    "`BOS` indicates the beginning of a string\n",
    "\n",
    "`EOS` indicates the end of a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def replace_all_caps(x):\n",
    "    \"Replace tokens in ALL CAPS by their lower version and add `TK_UP` before, if length > 1\"\n",
    "    res = []\n",
    "    for t in x:\n",
    "        if t.isupper() and len(t) > 1: res.append(TK_UP); res.append(t.lower())\n",
    "        else: res.append(t)\n",
    "    return res\n",
    "\n",
    "def deal_caps(x):\n",
    "    \"Replace all Capitalized tokens by their lower version and add `TK_MAJ` before.\"\n",
    "    res = []\n",
    "    for t in x:\n",
    "        if t == '': continue\n",
    "        if t[0].isupper() and len(t) > 1 and t[1:].islower(): res.append(TK_MAJ)\n",
    "        res.append(t.lower())\n",
    "    return res\n",
    "\n",
    "\"What does this function do? And why does it go last?\"\n",
    "\"Brackets each token with BOS and EOS tokens\"\n",
    "def add_eos_bos(x): return [BOS] + x + [EOS]\n",
    "\n",
    "default_post_rules = [deal_caps, replace_all_caps, add_eos_bos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'xxup', 'am', 'xxup', 'shouting']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_all_caps(['I', 'AM', 'SHOUTING'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxmaj', 'my', 'name', 'is', 'xxmaj', 'jeremy']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deal_caps(['My', 'name', 'is', 'Jeremy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Parallellizing the Tokenization Process\n",
    "Since tokenizing and applying those rules takes a bit of time, we'll parallelize it using `ProcessPoolExecutor` to go faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from spacy.symbols import ORTH\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def parallel(func, arr, max_workers=4):\n",
    "    # should specify what are the inputs func and arr?\n",
    "    if max_workers<2: results = list(progress_bar(map(func, enumerate(arr)), total=len(arr)))\n",
    "    else:\n",
    "        # use context manager to handle parallel processing case\n",
    "        with ProcessPoolExecutor(max_workers=max_workers) as ex:\n",
    "            return list(progress_bar(ex.map(func, enumerate(arr)), total=len(arr)))\n",
    "    if any([o is not None for o in results]): return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TokenizeProcessor(Processor):\n",
    "    # initialize max_workers to 1, because Windows 10 won't allow max_workers > 1\n",
    "    #def __init__(self, lang=\"en\", chunksize=2000, pre_rules=None, post_rules=None, max_workers=4): \n",
    "    def __init__(self, lang=\"en\", chunksize=2000, pre_rules=None, post_rules=None, max_workers=1): \n",
    "        self.chunksize,self.max_workers = chunksize,max_workers\n",
    "        # using spacy's tokenizer\n",
    "        self.tokenizer = spacy.blank(lang).tokenizer\n",
    "        for w in default_spec_tok:\n",
    "            # dictionary of default_spec_tok\n",
    "            self.tokenizer.add_special_case(w, [{ORTH: w}])\n",
    "        self.pre_rules  = default_pre_rules  if pre_rules  is None else pre_rules\n",
    "        self.post_rules = default_post_rules if post_rules is None else post_rules\n",
    "\n",
    "    def proc_chunk(self, args):\n",
    "        # specify inputs: what are i and chunk?\n",
    "        i,chunk = args\n",
    "        \n",
    "        # pre-process\n",
    "        chunk = [compose(t, self.pre_rules) for t in chunk]\n",
    "        # what does .pipe do?\n",
    "        docs = [[d.text for d in doc] for doc in self.tokenizer.pipe(chunk)]\n",
    "        \n",
    "        # post-process\n",
    "        docs = [compose(t, self.post_rules) for t in docs]\n",
    "        return docs\n",
    "\n",
    "    def __call__(self, items): \n",
    "        toks = []\n",
    "        if isinstance(items[0], Path): items = [read_file(i) for i in items]\n",
    "        chunks = [items[i: i+self.chunksize] for i in (range(0, len(items), self.chunksize))]\n",
    "        toks = parallel(self.proc_chunk, chunks, max_workers=self.max_workers)\n",
    "        return sum(toks, [])\n",
    "    \n",
    "    def proc1(self, item): return self.proc_chunk([item])[0]\n",
    "    \n",
    "    # what do these deprocessing functions do?\n",
    "    def deprocess(self, toks): return [self.deproc1(tok) for tok in toks]\n",
    "    # this one inserts blank space between characters \n",
    "    def deproc1(self, tok):    return \" \".join(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Instantiate the TokenizeProcessor() and explore the data a bit more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TokenizeProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'g', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'm', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', '.', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'g', 'xxeos'],\n",
       " ['xxbos', 'g', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'u', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'm', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'v', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'f', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'f', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'g', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'y', 'xxeos'],\n",
       " ['xxbos', '.', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'f', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'm', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'f', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'u', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'q', 'xxeos'],\n",
       " ['xxbos', 'u', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ',', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'f', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'w', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'v', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'y', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'f', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'w', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'j', 'xxeos'],\n",
       " ['xxbos', 'u', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'b', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'u', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'y', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'f', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', '.', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'm', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'f', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'u', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'v', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'g', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', ',', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', \"'\", 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'z', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'y', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', ',', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'f', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'g', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'u', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'm', 'xxeos'],\n",
       " ['xxbos', 'u', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', ',', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'b', 'xxeos'],\n",
       " ['xxbos', 'y', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'w', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'm', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', '.', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'w', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'u', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'y', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'b', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'u', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'v', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'y', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'k', 'xxeos'],\n",
       " ['xxbos', 'y', 'xxeos'],\n",
       " ['xxbos', ',', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'v', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'f', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'k', 'xxeos'],\n",
       " ['xxbos', 'u', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', '.', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'p', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'b', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'm', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'm', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'f', 'xxeos'],\n",
       " ['xxbos', 'f', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'k', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'w', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'k', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', \"'\", 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'b', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'y', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'u', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'm', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'w', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'g', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'f', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'u', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', '.', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'y', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'b', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'p', 'xxeos'],\n",
       " ['xxbos', 'p', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'b', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'w', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'g', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'v', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', '.', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'f', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'y', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'w', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'w', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'w', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'p', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'f', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'w', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'y', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'p', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'f', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'k', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', ',', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'u', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'b', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'u', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'k', 'xxeos'],\n",
       " ['xxbos', 'u', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', \"'\", 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'g', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', '.', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'w', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'w', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'y', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'k', 'xxeos'],\n",
       " ['xxbos', 'u', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'v', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'b', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'b', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'w', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'p', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'k', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'g', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'f', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'w', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'g', 'xxeos'],\n",
       " ['xxbos', '.', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'm', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'g', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', ',', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'w', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 's', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'c', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'u', 'xxeos'],\n",
       " ['xxbos', 'l', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'd', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'k', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'e', 'xxeos'],\n",
       " ['xxbos', 'p', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'f', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'm', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', 'u', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', 'g', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 't', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'f', 'xxeos'],\n",
       " ['xxbos', 'f', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'a', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'h', 'xxeos'],\n",
       " ['xxbos', 'o', 'xxeos'],\n",
       " ['xxbos', 'u', 'xxeos'],\n",
       " ['xxbos', 'r', 'xxeos'],\n",
       " ['xxbos', ' ', 'xxeos'],\n",
       " ['xxbos', 'i', 'xxeos'],\n",
       " ['xxbos', 'n', 'xxeos'],\n",
       " ['xxbos', '.', 'xxeos']]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hmmmm.... this is weird What's going on here?\n",
    "#      Makes a list with an item for each of the 900 characters in the text.\n",
    "#           Each item is a list with 3 elements: \n",
    "#                the character, bracketed by 'xxbos' and 'xxeos'\n",
    "#                so xxbos and xxeos flag the beginning and end of each item\n",
    "# Aha! This is the result of add_eos_bos(x), the last function in the post-processing default_post_rules!\n",
    "tp(il[:100][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['xxbos',\n",
       " 'xxmaj',\n",
       " 'once',\n",
       " 'again',\n",
       " 'xxmaj',\n",
       " 'mr.',\n",
       " 'xxmaj',\n",
       " 'costner',\n",
       " 'has',\n",
       " 'dragged',\n",
       " 'out',\n",
       " 'a',\n",
       " 'movie',\n",
       " 'for',\n",
       " 'far',\n",
       " 'longer',\n",
       " 'than',\n",
       " 'necessary',\n",
       " '.',\n",
       " 'xxmaj',\n",
       " 'aside',\n",
       " 'from',\n",
       " 'the',\n",
       " 'terrific',\n",
       " 'sea',\n",
       " 'rescue',\n",
       " 'sequences',\n",
       " ',',\n",
       " 'of',\n",
       " 'which',\n",
       " 'there',\n",
       " 'are',\n",
       " 'very',\n",
       " 'few',\n",
       " 'i',\n",
       " 'just',\n",
       " 'did',\n",
       " 'not',\n",
       " 'care',\n",
       " 'about',\n",
       " 'any',\n",
       " 'of',\n",
       " 'the',\n",
       " 'characters',\n",
       " '.',\n",
       " 'xxmaj',\n",
       " 'most',\n",
       " 'of',\n",
       " 'us',\n",
       " 'have',\n",
       " 'ghosts',\n",
       " 'in',\n",
       " 'the',\n",
       " 'closet',\n",
       " ',',\n",
       " 'and',\n",
       " 'xxmaj',\n",
       " 'costner',\n",
       " \"'s\",\n",
       " 'character',\n",
       " 'are',\n",
       " 'realized',\n",
       " 'early',\n",
       " 'on',\n",
       " ',',\n",
       " 'and',\n",
       " 'then',\n",
       " 'forgotten',\n",
       " 'until',\n",
       " 'much',\n",
       " 'later',\n",
       " ',',\n",
       " 'by',\n",
       " 'which',\n",
       " 'time',\n",
       " 'i',\n",
       " 'did',\n",
       " 'not',\n",
       " 'care',\n",
       " '.',\n",
       " 'xxmaj',\n",
       " 'the',\n",
       " 'character',\n",
       " 'we',\n",
       " 'should',\n",
       " 'really',\n",
       " 'care',\n",
       " 'about',\n",
       " 'is',\n",
       " 'a',\n",
       " 'very',\n",
       " 'cocky',\n",
       " ',',\n",
       " 'overconfident',\n",
       " 'xxmaj',\n",
       " 'ashton',\n",
       " 'xxmaj',\n",
       " 'kutcher',\n",
       " '.',\n",
       " 'xxmaj',\n",
       " 'the',\n",
       " 'problem',\n",
       " 'is',\n",
       " 'he',\n",
       " 'comes',\n",
       " 'off',\n",
       " 'as',\n",
       " 'kid',\n",
       " 'who',\n",
       " 'thinks',\n",
       " 'he',\n",
       " \"'s\",\n",
       " 'better',\n",
       " 'than',\n",
       " 'anyone',\n",
       " 'else',\n",
       " 'around',\n",
       " 'him',\n",
       " 'and',\n",
       " 'shows',\n",
       " 'no',\n",
       " 'signs',\n",
       " 'of',\n",
       " 'a',\n",
       " 'cluttered',\n",
       " 'closet',\n",
       " '.',\n",
       " 'xxmaj',\n",
       " 'his',\n",
       " 'only',\n",
       " 'obstacle',\n",
       " 'appears',\n",
       " 'to',\n",
       " 'be',\n",
       " 'winning',\n",
       " 'over',\n",
       " 'xxmaj',\n",
       " 'costner',\n",
       " '.',\n",
       " 'xxmaj',\n",
       " 'finally',\n",
       " 'when',\n",
       " 'we',\n",
       " 'are',\n",
       " 'well',\n",
       " 'past',\n",
       " 'the',\n",
       " 'half',\n",
       " 'way',\n",
       " 'point',\n",
       " 'of',\n",
       " 'this',\n",
       " 'stinker',\n",
       " ',',\n",
       " 'xxmaj',\n",
       " 'costner',\n",
       " 'tells',\n",
       " 'us',\n",
       " 'all',\n",
       " 'about',\n",
       " 'xxmaj',\n",
       " 'kutcher',\n",
       " \"'s\",\n",
       " 'ghosts',\n",
       " '.',\n",
       " 'xxmaj',\n",
       " 'we',\n",
       " 'are',\n",
       " 'told',\n",
       " 'why',\n",
       " 'xxmaj',\n",
       " 'kutcher',\n",
       " 'is',\n",
       " 'driven',\n",
       " 'to',\n",
       " 'be',\n",
       " 'the',\n",
       " 'best',\n",
       " 'with',\n",
       " 'no',\n",
       " 'prior',\n",
       " 'inkling',\n",
       " 'or',\n",
       " 'foreshadowing',\n",
       " '.',\n",
       " 'xxmaj',\n",
       " 'no',\n",
       " 'magic',\n",
       " 'here',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " 'all',\n",
       " 'i',\n",
       " 'could',\n",
       " 'do',\n",
       " 'to',\n",
       " 'keep',\n",
       " 'from',\n",
       " 'turning',\n",
       " 'it',\n",
       " 'off',\n",
       " 'an',\n",
       " 'hour',\n",
       " 'in',\n",
       " '.',\n",
       " 'xxeos']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the 900 characters of the first text item are mapped into 207 words, including special tokens and punctuation\n",
    "#      note that the beginning and end tokens are 'xxbos' and 'xxeos'\n",
    "print(len(tp(il[:100])[0]))\n",
    "tp(il[:100])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['xxbos',\n",
       " 'xxmaj',\n",
       " 'once',\n",
       " 'again',\n",
       " 'xxmaj',\n",
       " 'mr.',\n",
       " 'xxmaj',\n",
       " 'costner',\n",
       " 'has',\n",
       " 'dragged',\n",
       " 'out',\n",
       " 'a',\n",
       " 'movie',\n",
       " 'for',\n",
       " 'far',\n",
       " 'longer',\n",
       " 'than',\n",
       " 'necessary',\n",
       " '.',\n",
       " 'xxmaj',\n",
       " 'aside',\n",
       " 'from',\n",
       " 'the',\n",
       " 'terrific',\n",
       " 'sea',\n",
       " 'rescue',\n",
       " 'sequences',\n",
       " ',',\n",
       " 'of',\n",
       " 'which',\n",
       " 'there',\n",
       " 'are',\n",
       " 'very',\n",
       " 'few',\n",
       " 'i',\n",
       " 'just',\n",
       " 'did',\n",
       " 'not',\n",
       " 'care',\n",
       " 'about',\n",
       " 'any',\n",
       " 'of',\n",
       " 'the',\n",
       " 'characters',\n",
       " '.',\n",
       " 'xxmaj',\n",
       " 'most',\n",
       " 'of',\n",
       " 'us',\n",
       " 'have',\n",
       " 'ghosts',\n",
       " 'in',\n",
       " 'the',\n",
       " 'closet',\n",
       " ',',\n",
       " 'and',\n",
       " 'xxmaj',\n",
       " 'costner',\n",
       " \"'s\",\n",
       " 'character',\n",
       " 'are',\n",
       " 'realized',\n",
       " 'early',\n",
       " 'on',\n",
       " ',',\n",
       " 'and',\n",
       " 'then',\n",
       " 'forgotten',\n",
       " 'until',\n",
       " 'much',\n",
       " 'later',\n",
       " ',',\n",
       " 'by',\n",
       " 'which',\n",
       " 'time',\n",
       " 'i',\n",
       " 'did',\n",
       " 'not',\n",
       " 'care',\n",
       " '.',\n",
       " 'xxmaj',\n",
       " 'the',\n",
       " 'character',\n",
       " 'we',\n",
       " 'should',\n",
       " 'really',\n",
       " 'care',\n",
       " 'about',\n",
       " 'is',\n",
       " 'a',\n",
       " 'very',\n",
       " 'cocky',\n",
       " ',',\n",
       " 'overconfident',\n",
       " 'xxmaj',\n",
       " 'ashton',\n",
       " 'xxmaj',\n",
       " 'kutcher',\n",
       " '.',\n",
       " 'xxmaj',\n",
       " 'the',\n",
       " 'problem',\n",
       " 'is',\n",
       " 'he',\n",
       " 'comes',\n",
       " 'off',\n",
       " 'as',\n",
       " 'kid',\n",
       " 'who',\n",
       " 'thinks',\n",
       " 'he',\n",
       " \"'s\",\n",
       " 'better',\n",
       " 'than',\n",
       " 'anyone',\n",
       " 'else',\n",
       " 'around',\n",
       " 'him',\n",
       " 'and',\n",
       " 'shows',\n",
       " 'no',\n",
       " 'signs',\n",
       " 'of',\n",
       " 'a',\n",
       " 'cluttered',\n",
       " 'closet',\n",
       " '.',\n",
       " 'xxmaj',\n",
       " 'his',\n",
       " 'only',\n",
       " 'obstacle',\n",
       " 'appears',\n",
       " 'to',\n",
       " 'be',\n",
       " 'winning',\n",
       " 'over',\n",
       " 'xxmaj',\n",
       " 'costner',\n",
       " '.',\n",
       " 'xxmaj',\n",
       " 'finally',\n",
       " 'when',\n",
       " 'we',\n",
       " 'are',\n",
       " 'well',\n",
       " 'past',\n",
       " 'the',\n",
       " 'half',\n",
       " 'way',\n",
       " 'point',\n",
       " 'of',\n",
       " 'this',\n",
       " 'stinker',\n",
       " ',',\n",
       " 'xxmaj',\n",
       " 'costner',\n",
       " 'tells',\n",
       " 'us',\n",
       " 'all',\n",
       " 'about',\n",
       " 'xxmaj',\n",
       " 'kutcher',\n",
       " \"'s\",\n",
       " 'ghosts',\n",
       " '.',\n",
       " 'xxmaj',\n",
       " 'we',\n",
       " 'are',\n",
       " 'told',\n",
       " 'why',\n",
       " 'xxmaj',\n",
       " 'kutcher',\n",
       " 'is',\n",
       " 'driven',\n",
       " 'to',\n",
       " 'be',\n",
       " 'the',\n",
       " 'best',\n",
       " 'with',\n",
       " 'no',\n",
       " 'prior',\n",
       " 'inkling',\n",
       " 'or',\n",
       " 'foreshadowing',\n",
       " '.',\n",
       " 'xxmaj',\n",
       " 'no',\n",
       " 'magic',\n",
       " 'here',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " 'all',\n",
       " 'i',\n",
       " 'could',\n",
       " 'do',\n",
       " 'to',\n",
       " 'keep',\n",
       " 'from',\n",
       " 'turning',\n",
       " 'it',\n",
       " 'off',\n",
       " 'an',\n",
       " 'hour',\n",
       " 'in',\n",
       " '.',\n",
       " 'xxeos']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tp(il[:100])[0]))\n",
    "tp(il[:100])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"xxbos  xxmaj  once  again  xxmaj  mr.  xxmaj  costner  has  dragged  out  a  movie  for  far  longer  than  necessary  .  xxmaj  aside  from  the  terrific  sea  rescue  sequences  ,  of  which  there  are  very  few  i  just  did  not  care  about  any  of  the  characters  .  xxmaj  most  of  us  have  ghosts  in  the  closet  ,  and  xxmaj  costner  's  character  are  realized  early  on  ,  and  then  forgotten  until  much  later  ,  by  which  time  i  did  not  care  .  xxmaj  the  character  we  should  really  care  about  is  a  very  cocky  ,  overconfident  xxmaj  ashton  xxmaj  kutcher  .  xxmaj  the  problem  is  he  comes  off  as  kid  who  thinks  he  's  better  than  anyone  else  around  him  and  shows  no  signs  of  a  cluttered  closet  .  xxmaj  his  only  obstacle  appears  to  be  winning  over  xxmaj  costner  .  xxmaj  finally  when  we  are  well  past  the  half  way  point  of  this  stinker  ,  xxmaj  costner  tells  us  all  about  xxmaj  kutcher  's  ghosts  .  xxmaj  we  are  told  why  xxmaj  kutcher  is  driven  to  be  the  best  with  no  prior  inkling  or  foreshadowing  .  xxmaj  no  magic  here  ,  it  was  all  i  could  do  to  keep  from  turning  it  off  an  hour  in  .  xxeos\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'  '.join(tp(il[:100])[0])[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'xxbos  xxmaj  once  again  xxmaj  mr.  xxmaj  costner  has  dragged  out  a  movie  for  far  longer  than  necessary  .  xxmaj  aside  from  the  terrific  sea  rescue  sequences  ,  of  which  there  are  very  few  i  just  did  not  care  about  any  of  the  characters  .  xxmaj  most  of  us  have  ghosts  in  the  closet  ,  and  xxmaj'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'  '.join(tp(il[:100])[0])[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'xxbos  xxmaj  once  again  xxmaj  mr.  xxmaj  costner  has  dragged  out  a  movie  for  far  longer  than  necessary  .  xxmaj  aside  from  the  terrific  sea  rescue  sequences  ,  of  which  there  are  very  few  i  just  did  not  care  about  any  of  the  characters  .  xxmaj  most  of  us  have  ghosts  in  the  closet  ,  and  xxmaj'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'  '.join(tp(il[:100])[0])[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1451"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('  '.join(tp(il[:100])[0])[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Numericalizing the text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have tokenized our texts, we replace each token by an individual number, this is called numericalizing. Again, we do this with a processor (not so different from the `CategoryProcessor`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 12 video](https://course.fast.ai/videos/?lesson=12&t=5491)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import collections\n",
    "\n",
    "class NumericalizeProcessor(Processor):\n",
    "    def __init__(self, vocab=None, max_vocab=60000, min_freq=2): \n",
    "        self.vocab,self.max_vocab,self.min_freq = vocab,max_vocab,min_freq\n",
    "    \n",
    "    def __call__(self, items):\n",
    "        #The vocab is defined on the first use.\n",
    "        if self.vocab is None:\n",
    "            freq = Counter(p for o in items for p in o)\n",
    "            # include a word only if it occurs more than self.min_freq times in the text\n",
    "            self.vocab = [o for o,c in freq.most_common(self.max_vocab) if c >= self.min_freq]\n",
    "            for o in reversed(default_spec_tok):\n",
    "                if o in self.vocab: self.vocab.remove(o)\n",
    "                self.vocab.insert(0, o)\n",
    "        if getattr(self, 'otoi', None) is None:\n",
    "            self.otoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.vocab)}) \n",
    "        return [self.proc1(o) for o in items]\n",
    "    def proc1(self, item):  return [self.otoi[o] for o in item]\n",
    "    \n",
    "    def deprocess(self, idxs):\n",
    "        assert self.vocab is not None\n",
    "        return [self.deproc1(idx) for idx in idxs]\n",
    "    def deproc1(self, idx): return [self.vocab[i] for i in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Splitting the data into training and validation sets\n",
    "For text classification, we will split by the grand parent folder as before, but for language modeling, we take all the texts and just put 10% aside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = SplitData.split_by_func(il, partial(random_splitter, p_valid=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SplitData\n",
       "Train: TextList (90085 items)\n",
       "[WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test/neg/0_2.txt'), WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test/neg/10000_4.txt'), WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test/neg/10001_1.txt'), WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test/neg/10002_3.txt'), WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test/neg/10003_3.txt'), WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test/neg/10004_2.txt'), WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test/neg/10005_2.txt'), WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test/neg/10006_2.txt'), WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test/neg/10007_4.txt'), WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test/neg/10008_4.txt')...]\n",
       "Path: C:\\Users\\cross-entropy\\.fastai\\data\\imdb\n",
       "Valid: TextList (9915 items)\n",
       "[WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test/neg/10010_2.txt'), WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test/neg/1002_3.txt'), WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test/neg/10038_4.txt'), WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test/neg/10049_1.txt'), WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test/neg/10054_3.txt'), WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test/neg/10058_2.txt'), WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test/neg/10061_4.txt'), WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test/neg/10068_3.txt'), WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test/neg/10071_2.txt'), WindowsPath('C:/Users/cross-entropy/.fastai/data/imdb/test/neg/10076_3.txt')...]\n",
       "Path: C:\\Users\\cross-entropy\\.fastai\\data\\imdb"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Labeling\n",
    "When we do language modeling, we will infer the labels from the text during training, so there's no need to label. The training loop expects labels however, so we need to add dummy ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proc_tok,proc_num = TokenizeProcessor(max_workers=8),NumericalizeProcessor()\n",
    "proc_tok,proc_num = TokenizeProcessor(max_workers=1),NumericalizeProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='46' class='' max='46', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [46/46 08:57<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 00:58<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 54s\n"
     ]
    }
   ],
   "source": [
    "%time ll = label_by_func(sd, lambda x: 0, proc_x = [proc_tok,proc_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the items have been processed they will become list of numbers. We can still access the underlying raw data in `x_obj` for the text and `y_obj` for the targets (which in this case are all dummies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LabeledData.x_obj of LabeledData\n",
       "x: TextList (90085 items)\n",
       "[[2, 7, 301, 193, 7, 596, 7, 5444, 61, 3435, 60, 12, 29, 28, 248, 1135, 93, 1700, 9, 7, 1216, 51, 8, 1353, 1615, 2073, 828, 10, 13, 79, 54, 38, 70, 190, 18, 56, 87, 37, 474, 59, 120, 13, 8, 121, 9, 7, 110, 13, 202, 41, 3017, 17, 8, 4844, 10, 11, 7, 5444, 22, 123, 38, 1695, 432, 34, 10, 11, 115, 1533, 385, 94, 328, 10, 47, 79, 75, 18, 87, 37, 474, 9, 7, 8, 123, 90, 156, 83, 474, 59, 15, 12, 70, 9452, 10, 37895, 7, 8476, 7, 10744, 9, 7, 8, 462, 15, 39, 297, 142, 26, 543, 49, 1212, 39, 22, 146, 93, 270, 345, 209, 108, 11, 294, 74, 3670, 13, 12, 16872, 4844, 9, 7, 40, 82, 13455, 738, 14, 43, 1769, 143, 7, 5444, 9, 7, 449, 68, 90, 38, 89, 520, 8, 331, 116, 243, 13, 19, 3972, 10, 7, 5444, 715, 202, 44, 59, 7, 10744, 22, 3017, 9, 7, 90, 38, 594, 154, 7, 10744, 15, 2084, 14, 43, 8, 139, 27, 74, 2716, 16667, 55, 12049, 9, 7, 74, 1298, 148, 10, 16, 25, 44, 18, 95, 58, 14, 409, 51, 1618, 16, 142, 48, 563, 17, 9, 3], [2, 7, 19, 15, 48, 509, 13, 154, 8, 2163, 13, 212, 125, 38, 8, 187, 9, 7, 3799, 11, 368, 10, 54, 22, 83, 181, 295, 168, 148, 9, 12, 622, 473, 13, 8, 115, 1189, 23, 15267, 2014, 13, 7, 1775, 23, 2326, 11, 7, 1775, 7, 5567, 10, 49, 160, 276, 14083, 128, 235, 143, 20, 46, 38, 2114, 13, 137, 10, 11, 137, 89, 9, 7, 58, 35, 1326, 27, 19, 42, 10, 159, 84, 7, 183, 7, 690, 7, 513, 10, 7, 36173, 55, 126, 7, 183, 7, 786, 7, 5201, 28, 7, 1775, 23, 2326, 10, 55, 7, 16480, 2778, 8, 7, 2605, 10, 7, 2024, 7, 2795, 55, 7, 2195, 28, 7, 1775, 7, 5567, 11, 84, 8, 164, 833, 9, 7, 1775, 23, 2326, 22, 2215, 7148, 430, 640, 179, 19, 31, 17080, 45, 8, 2879, 10, 11, 18, 167, 152, 1583, 64, 8, 2132, 7, 963, 7, 7543, 25, 422, 17, 19, 31, 66, 7, 11, 154, 8, 2132, 91, 39, 237, 320, 8, 2496, 187, 123, 66, 7, 51, 7, 1663, 19107, 10, 191, 31, 18, 160, 130, 27, 7, 963, 7, 7543, 61, 108, 417, 8, 2496, 187, 2167, 123, 10, 11, 45, 242, 17, 7, 1663, 40, 123, 1095, 10, 79, 112, 16, 664, 17312, 92, 24, 7, 463, 10, 19, 15, 347, 23, 999, 212, 1238, 9, 7, 54, 38, 3415, 146, 125, 14, 84, 10, 11, 63, 32, 83, 204, 14, 84, 19, 42, 10, 126, 7, 8995, 7, 330, 10, 79, 15, 2342, 12, 12157, 986, 30, 61, 146, 137, 11, 12, 146, 246, 9, 7, 8, 82, 169, 20, 112, 19, 45, 44, 295, 168, 25, 12, 549, 517, 34, 8, 376, 23, 8, 665, 25, 239, 2337, 10, 79, 297, 519, 14, 254, 72, 28, 8, 506, 31, 414, 23, 30, 37, 203, 9, 224, 124, 182, 9, 3], [2, 7, 107, 13, 44, 18, 741, 165, 5238, 13334, 10, 49, 30074, 512, 63, 46, 85, 12, 924, 6898, 467, 80, 31097, 9, 7, 44, 46, 58, 15, 2687, 11, 1197, 276, 102, 11, 137, 53, 0, 349, 13, 3917, 9, 24, 7, 8, 29, 91, 35, 213, 69, 93, 750, 247, 14, 1267, 64, 15, 184, 34, 178, 90, 199, 492, 45, 8, 7625, 7, 54, 15, 37, 12, 693, 2176, 123, 17, 19, 29, 10, 565, 28, 8, 4601, 231, 10, 49, 15, 103, 8, 82, 42, 27, 331, 12, 1186, 9, 24, 7, 963, 7, 7543, 11, 7, 988, 7, 20927, 38, 218, 2154, 52536, 11, 7, 0, 123, 15, 56, 26, 94, 12, 1006, 26, 8, 3917, 9, 18, 20928, 53, 108, 228, 51, 8, 392, 9, 24, 7, 8, 29, 15, 1063, 27, 1118, 564, 11, 7, 2662, 7, 3170, 15772, 96, 100, 1500, 163, 5903, 27, 2914, 1701, 2519, 9, 7, 54, 15, 206, 94, 74, 131, 11, 16, 15, 12, 219, 462, 68, 32, 3870, 28, 74, 23, 42, 9, 7, 1278, 1468, 10, 565, 51, 7, 7543, 11, 8, 4601, 231, 11, 1278, 98, 64, 46, 1782, 9, 24, 7, 8, 82, 127, 334, 100, 20, 78, 512, 15, 8, 4601, 231, 11, 8, 7834, 30, 46, 199, 171, 47, 5742, 10, 37, 634, 1510, 1186, 352, 13334, 9, 24, 7, 789, 262, 51, 19, 626, 11, 126, 7987, 615, 382, 11, 264, 319, 9, 7, 45, 10460, 46, 41, 121, 32, 474, 59, 10, 12, 292, 13, 469, 11, 181, 30, 164, 171, 17, 8, 196, 9, 3], [2, 7, 37, 76, 8, 7, 4965, 95, 943, 778, 310, 447, 10, 11, 284, 7, 2662, 7, 2154, 15, 74, 26786, 23, 365, 39, 22, 347, 14, 620, 68, 16, 297, 14, 217, 2811, 212, 118, 9, 7, 8, 8639, 404, 11, 1111, 34684, 86, 2497, 17, 238, 11, 31, 10, 8, 18561, 13, 8, 7, 11428, 660, 29, 337, 25, 17, 390, 6689, 10, 8, 137, 572, 12, 162, 2000, 14, 276, 145, 22, 16286, 15268, 1225, 11, 8801, 137, 9, 7, 19, 25, 42, 13, 8, 128, 1775, 23, 2326, 118, 18, 233, 26, 12, 543, 11, 476, 10, 82, 14, 126, 111, 328, 11, 3348, 9, 7, 963, 7, 7543, 11, 7, 988, 7, 20927, 38, 17313, 27, 1154, 481, 385, 12, 3391, 1279, 9661, 59, 14, 159, 72, 17, 7790, 922, 143, 12, 5218, 27, 1608, 9453, 9, 18, 517, 16, 14, 7, 2662, 28, 941, 11, 6645, 937, 72, 8, 305, 121, 11, 1559, 9, 7, 30, 18, 2051, 310, 584, 28, 1618, 60, 7, 874, 23, 1438, 374, 9, 7, 1775, 23, 2326, 11, 5567, 225, 41, 99, 806, 891, 45, 19, 75, 10, 11, 153, 18, 160, 521, 218, 80, 3649, 26, 13334, 10, 17, 77, 683, 46, 1609, 1065, 17, 19, 29, 9, 7, 16, 22, 59, 7626, 247, 13, 42, 231, 3650, 1618, 40, 162, 34, 8, 102, 231, 14, 8, 243, 32, 186, 668, 3183, 17, 2628, 1568, 13, 2864, 9, 7, 166, 19, 15, 12, 29, 10, 114, 37, 12, 632, 52, 18, 491, 1146, 473, 77, 75, 17532, 44, 8, 394, 131, 1260, 17, 19, 29, 10, 30, 54, 86, 128, 10, 11, 46, 1610, 1265, 9, 18, 207, 8, 574, 168, 19, 20, 310, 34, 289, 25, 0, 13, 1489, 11, 56, 417, 198, 142, 8, 22504, 9, 7, 54, 38, 127, 198, 18, 152, 386, 59, 16, 10, 42, 2115, 12, 150, 27, 12, 11951, 11, 8, 102, 15, 7, 20927, 22, 678, 3806, 7208, 9, 7, 1370, 367, 19, 29, 15, 53, 9354, 22, 7007, 9, 7, 1167, 1944, 1876, 16, 63, 18, 167, 4995, 11, 18, 58, 35, 250, 53, 6690, 10, 7, 30, 18, 167, 89, 1854, 16, 4645, 53, 626, 9, 381, 425, 10, 19108, 9, 3], [2, 7, 8434, 1332, 36, 118, 15, 37, 12, 3731, 680, 28, 111, 33, 83, 38, 664, 22505, 9, 7, 80, 9355, 1121, 2334, 38, 2786, 13, 3336, 325, 729, 263, 3732, 9, 7, 30, 494, 7, 8434, 1332, 38, 821, 125, 27, 8, 11429, 13, 1675, 14, 2828, 798, 28, 143, 127, 615, 50, 7, 17, 19, 46, 1984, 3253, 10, 80, 9662, 10, 30, 269, 1813, 11, 22120, 93, 9143, 10, 2499, 2334, 700, 24973, 9, 24, 7, 48204, 62, 3806, 15, 12, 1008, 13, 12, 31, 47, 7, 19109, 7, 8838, 27, 8, 187, 441, 11, 7, 26157, 7, 20929, 11, 7, 6968, 7, 8517, 17, 8, 472, 9, 7, 8, 230, 715, 12, 81, 13, 4855, 134, 11, 3936, 17, 11, 209, 7, 6346, 316, 8, 7, 1057, 1575, 13, 6218, 9, 7, 8434, 1654, 8, 212, 51, 8, 4864, 104, 8, 3856, 1109, 10, 6691, 14, 43, 2496, 10, 52, 54, 38, 7, 15592, 58575, 10, 346, 17, 334, 7715, 10, 7, 1049, 6846, 55, 8, 19661, 16120, 13, 8, 20592, 9, 7, 30, 16, 15, 56, 1847, 5153, 10, 8, 5312, 1965, 15, 353, 19379, 9, 24, 7, 2081, 7, 0, 314, 8, 1587, 12050, 267, 49, 751, 28, 8, 9039, 8477, 231, 49, 237, 1394, 34, 117, 94, 10612, 9, 7, 71, 15, 48, 1587, 10, 8802, 10, 89, 4039, 7, 1057, 556, 11, 701, 730, 8, 847, 9, 7, 57, 1887, 2047, 13, 2933, 2925, 36, 58576, 3157, 10, 10678, 10, 2895, 10, 1117, 10, 741, 92, 11, 11952, 33, 38, 8, 139, 312, 14, 126, 19, 455, 11, 295, 127, 425, 9, 7, 71, 15269, 19, 681, 4500, 539, 27, 48, 4712, 1157, 13, 4100, 9, 18, 657, 65, 83, 67, 524, 234, 359, 28, 57, 9, 7, 71, 83, 1032, 16, 9, 3], [2, 12, 172, 169, 582, 14, 88, 153, 168, 21, 7, 23934, 21, 96, 34, 8, 42, 517, 10, 8, 576, 15, 12, 4950, 23, 4938, 11, 8, 170, 15, 479, 2074, 14, 113, 202, 408, 154, 39, 91, 64, 39, 91, 36, 22968, 13830, 92, 5755, 10, 1410, 88, 10, 4926, 33, 163, 40, 1209, 9, 7, 34, 8, 102, 517, 10, 8, 7, 644, 349, 45, 242, 15, 70, 959, 2330, 9, 7, 52, 18, 274, 560, 4888, 54, 85, 99, 218, 69, 11, 361, 430, 45, 8, 187, 75, 50, 7, 19, 31, 15, 394, 36, 172, 109, 19, 231, 61, 4951, 14, 191, 7928, 11, 20593, 17, 40, 501, 33, 11, 8887, 36, 135, 73, 90, 43, 17, 12, 1915, 44767, 229, 277, 2302, 2295, 150, 66, 33, 9, 7, 37, 14, 755, 8, 21, 742, 21, 1287, 36, 451, 10, 109, 0, 92, 7, 691, 16, 9, 36, 194, 33, 3], [2, 7, 19, 7, 1049, 201, 31, 61, 14, 43, 42, 13, 8, 12436, 18, 41, 130, 9, 24, 18, 25, 37, 1854, 13, 120, 1974, 222, 518, 2473, 11, 17533, 10, 30, 19, 15, 460, 452, 713, 12, 313, 123, 9, 24, 7, 277, 576, 15, 4950, 11, 4938, 26, 12, 929, 13, 2733, 14797, 45, 8, 922, 13, 40, 356, 9, 39, 103, 61, 12, 3222, 9083, 10, 30, 18, 78, 37, 864, 60, 135, 20, 404, 51, 9, 7, 40, 1126, 23, 3009, 186, 60, 11, 9555, 108, 1995, 9, 24, 7, 316, 8, 272, 12, 3662, 23, 1426, 12158, 10, 11, 45, 330, 39, 2036, 104, 37896, 11, 3504, 5904, 11, 5280, 8, 557, 13, 352, 546, 9, 7, 46, 38, 44, 1587, 10, 13, 286, 10, 345, 90, 73, 35, 474, 59, 8, 211, 20, 39, 638, 1711, 80, 4306, 205, 14, 8, 10461, 9, 7, 39, 15773, 872, 14, 177, 825, 10, 11, 20, 15, 64, 240, 108, 1021, 9, 24, 7, 53, 18, 322, 10, 12, 70, 675, 29, 20, 15, 475, 11, 70, 577, 26, 7, 10279, 7, 48205, 132, 2160, 11, 56, 2395, 40, 75, 2506, 557, 9, 3], [2, 7, 129, 12, 214, 23, 75, 354, 13, 7, 980, 31, 10, 18, 862, 69, 93, 19, 9, 18, 197, 35, 83, 43, 2525, 14, 943, 14, 94, 10, 26, 19, 29, 15, 56, 52, 357, 9, 7, 8, 81, 252, 43, 8, 16668, 742, 138, 158, 144, 10, 2312, 18, 95, 35, 771, 8, 398, 137, 10, 8, 946, 46, 461, 1796, 10, 11, 8, 1220, 21, 2507, 21, 7, 980, 81, 9, 7, 63, 32, 160, 1957, 109, 128, 7, 980, 118, 380, 121, 10, 1638, 11, 1260, 20, 327, 117, 21, 285, 21, 10, 0, 52, 10, 115, 5850, 736, 13, 19, 29, 9, 7, 637, 10, 12, 14798, 175, 95, 41, 594, 32, 109, 19, 29, 25, 184, 14, 837, 359, 10, 11, 20, 22, 37, 12, 67, 169, 17, 77, 308, 9, 24, 7, 466, 13, 21, 7, 1495, 21, 7, 13688, 96, 40, 192, 17, 19, 29, 15, 37, 83, 69, 93, 12, 2010, 10, 11, 933, 32, 199, 12, 8158, 354, 10, 32, 58, 35, 387, 14, 2752, 163, 19, 473, 13, 31, 9, 24, 264, 124, 182, 3], [2, 21, 7, 6391, 7, 551, 21, 715, 13, 12, 3791, 341, 175, 7, 980, 260, 49, 751, 17, 53, 27, 12, 145, 129, 6969, 47, 57, 219, 19662, 49, 15, 12, 850, 9, 7, 19, 874, 507, 15, 59, 1354, 1375, 5265, 11, 1354, 1375, 711, 10, 711, 10, 11, 69, 711, 9, 7, 32, 259, 98, 14, 84, 8, 361, 93, 4316, 196, 13, 298, 26, 46, 711, 34, 8, 2625, 10, 711, 11, 320, 397, 1518, 10, 711, 11, 98, 12, 9710, 10, 711, 11, 1240, 11, 1240, 11, 711, 10, 711, 34, 2748, 7262, 10, 2836, 60, 11, 711, 10, 538, 9, 26, 32, 370, 2257, 1079, 28, 158, 14, 601, 9, 7, 8, 1586, 52537, 13, 12, 81, 15, 37, 6798, 14, 1430, 12, 31, 27, 378, 149, 389, 1086, 10, 12, 11346, 196, 10, 11, 74, 212, 10, 74, 880, 10, 74, 369, 55, 1037, 10, 74, 1250, 459, 92, 56, 11775, 0, 9, 36, 12643, 33, 3], [2, 7, 2727, 1676, 24394, 17, 7, 18275, 7, 18276, 41, 12, 214, 23, 2041, 74, 23, 10408, 7060, 27, 8, 7, 39764, 13, 7, 3832, 10, 30, 64, 575, 68, 8, 26787, 7, 4927, 480, 751, 28, 12, 764, 7, 2258, 27, 1857, 551, 10, 2161, 1122, 10, 11, 65, 10613, 1128, 34, 8, 951, 1804, 66, 3856, 7, 1109, 23, 7, 1677, 749, 61, 12, 7627, 15939, 258, 208, 12, 244, 26788, 209, 8, 7988, 9, 7, 16, 15, 70, 1250, 34, 8, 10135, 10, 30075, 23, 53, 1234, 10, 9902, 1586, 34, 81, 9, 7, 2926, 7, 16287, 36, 48, 24974, 563, 7061, 28, 7, 2486, 7, 8596, 33, 427, 16, 12, 8128, 10, 76, 174, 71, 22, 8058, 27, 11266, 7, 1698, 7, 17314, 36, 17, 12159, 113, 23, 72, 11, 4146, 1122, 33, 9, 7, 103, 67, 96, 7, 4357, 7, 18008, 26, 7, 2926, 22, 23447, 2989, 10, 12, 28295, 2062, 49, 22, 1359, 2457, 34, 8, 317, 10, 11, 7, 5905, 7, 7544, 417, 816, 36, 49, 345, 66, 33, 9, 7, 8, 1791, 692, 13, 7, 10078, 248, 52538, 8, 212, 754, 34, 8, 7, 1677, 23935, 10, 11, 65, 13, 8, 762, 374, 38, 203, 398, 9, 7, 47, 8, 75, 13, 8, 219, 0, 2005, 10, 110, 798, 105, 41, 85, 215, 9, 194, 382, 124, 264, 51, 4, 224, 194, 3]...]\n",
       "Path: C:\\Users\\cross-entropy\\.fastai\\data\\imdb\n",
       "y: ItemList (90085 items)\n",
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0...]\n",
       "Path: C:\\Users\\cross-entropy\\.fastai\\data\\imdb\n",
       ">"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numericalized text lists\n",
    "ll.train.x_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"xxbos xxmaj once again xxmaj mr. xxmaj costner has dragged out a movie for far longer than necessary . xxmaj aside from the terrific sea rescue sequences , of which there are very few i just did not care about any of the characters . xxmaj most of us have ghosts in the closet , and xxmaj costner 's character are realized early on , and then forgotten until much later , by which time i did not care . xxmaj the character we should really care about is a very cocky , overconfident xxmaj ashton xxmaj kutcher . xxmaj the problem is he comes off as kid who thinks he 's better than anyone else around him and shows no signs of a cluttered closet . xxmaj his only obstacle appears to be winning over xxmaj costner . xxmaj finally when we are well past the half way point of this stinker , xxmaj costner tells us all about xxmaj kutcher 's ghosts . xxmaj we are told why xxmaj kutcher is driven to be the best with no prior inkling or foreshadowing . xxmaj no magic here , it was all i could do to keep from turning it off an hour in . xxeos\""
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is the text in the first review\n",
    "ll.train.x_obj(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Save the labels`\n",
    "Since the preprocessing takes time, we save the intermediate result using pickle. \n",
    "\n",
    "Don't use`lambda` functions in your processors or they won't be able to pickle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ll, open(path/'ld.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = pickle.load(open(path/'ld.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Batching for Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a bit of work to convert our `LabelList` in a `DataBunch` as we don't just want batches of IMDB reviews. We want to stream through all the concatenated texts. We also have to prepare the targets that are the newt words in the text. All of this is done with the next object called `LM_PreLoader`. At the beginning of each epoch, it'll shuffle the articles (if `shuffle=True`) and create a big stream by concatenating all of them. We divide this big stream in `bs` smaller streams. That we will read in chunks of bptt length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 12 video](https://course.fast.ai/videos/?lesson=12&t=5565)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just using those for illustration purposes, they're not used otherwise.\n",
    "from IPython.display import display,HTML\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say our stream is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream = \"\"\"\n",
    "In this notebook, we will go back over the example of classifying movie reviews we studied in part 1 and dig deeper under the surface. \n",
    "First we will look at the processing steps necessary to convert text into numbers and how to customize it. By doing this, we'll have another example of the Processor used in the data block API.\n",
    "Then we will study how we build a language model and train it.\\n\n",
    "\"\"\"\n",
    "tokens = np.array(tp([stream])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to split the data into 6 batches of 15 tokens each.\n",
    "Here, the use of `bs` to denote the `number of batches` is potentially confusing because we've come to associate `bs` with `batch size`, so I've replaced `bs` with `n_batches`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos</td>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>in</td>\n",
       "      <td>this</td>\n",
       "      <td>notebook</td>\n",
       "      <td>,</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>go</td>\n",
       "      <td>back</td>\n",
       "      <td>over</td>\n",
       "      <td>the</td>\n",
       "      <td>example</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>classifying</td>\n",
       "      <td>movie</td>\n",
       "      <td>reviews</td>\n",
       "      <td>we</td>\n",
       "      <td>studied</td>\n",
       "      <td>in</td>\n",
       "      <td>part</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>dig</td>\n",
       "      <td>deeper</td>\n",
       "      <td>under</td>\n",
       "      <td>the</td>\n",
       "      <td>surface</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>first</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>look</td>\n",
       "      <td>at</td>\n",
       "      <td>the</td>\n",
       "      <td>processing</td>\n",
       "      <td>steps</td>\n",
       "      <td>necessary</td>\n",
       "      <td>to</td>\n",
       "      <td>convert</td>\n",
       "      <td>text</td>\n",
       "      <td>into</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>numbers</td>\n",
       "      <td>and</td>\n",
       "      <td>how</td>\n",
       "      <td>to</td>\n",
       "      <td>customize</td>\n",
       "      <td>it</td>\n",
       "      <td>.</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>by</td>\n",
       "      <td>doing</td>\n",
       "      <td>this</td>\n",
       "      <td>,</td>\n",
       "      <td>we</td>\n",
       "      <td>'ll</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>another</td>\n",
       "      <td>example</td>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>processor</td>\n",
       "      <td>used</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>data</td>\n",
       "      <td>block</td>\n",
       "      <td>api</td>\n",
       "      <td>.</td>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>then</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>study</td>\n",
       "      <td>how</td>\n",
       "      <td>we</td>\n",
       "      <td>build</td>\n",
       "      <td>a</td>\n",
       "      <td>language</td>\n",
       "      <td>model</td>\n",
       "      <td>and</td>\n",
       "      <td>train</td>\n",
       "      <td>it</td>\n",
       "      <td>.</td>\n",
       "      <td>\\n\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_batches,seq_len = 6,15\n",
    "d_tokens = np.array([tokens[i*seq_len:(i+1)*seq_len] for i in range(n_batches)])\n",
    "df = pd.DataFrame(d_tokens)\n",
    "display(HTML(df.to_html(index=False,header=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>xxbos</td>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>in</td>\n",
       "      <td>this</td>\n",
       "      <td>notebook</td>\n",
       "      <td>,</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>go</td>\n",
       "      <td>back</td>\n",
       "      <td>over</td>\n",
       "      <td>the</td>\n",
       "      <td>example</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>classifying</td>\n",
       "      <td>movie</td>\n",
       "      <td>reviews</td>\n",
       "      <td>we</td>\n",
       "      <td>studied</td>\n",
       "      <td>in</td>\n",
       "      <td>part</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>dig</td>\n",
       "      <td>deeper</td>\n",
       "      <td>under</td>\n",
       "      <td>the</td>\n",
       "      <td>surface</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>first</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>look</td>\n",
       "      <td>at</td>\n",
       "      <td>the</td>\n",
       "      <td>processing</td>\n",
       "      <td>steps</td>\n",
       "      <td>necessary</td>\n",
       "      <td>to</td>\n",
       "      <td>convert</td>\n",
       "      <td>text</td>\n",
       "      <td>into</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>numbers</td>\n",
       "      <td>and</td>\n",
       "      <td>how</td>\n",
       "      <td>to</td>\n",
       "      <td>customize</td>\n",
       "      <td>it</td>\n",
       "      <td>.</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>by</td>\n",
       "      <td>doing</td>\n",
       "      <td>this</td>\n",
       "      <td>,</td>\n",
       "      <td>we</td>\n",
       "      <td>'ll</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>another</td>\n",
       "      <td>example</td>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>processor</td>\n",
       "      <td>used</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>data</td>\n",
       "      <td>block</td>\n",
       "      <td>api</td>\n",
       "      <td>.</td>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>then</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>study</td>\n",
       "      <td>how</td>\n",
       "      <td>we</td>\n",
       "      <td>build</td>\n",
       "      <td>a</td>\n",
       "      <td>language</td>\n",
       "      <td>model</td>\n",
       "      <td>and</td>\n",
       "      <td>train</td>\n",
       "      <td>it</td>\n",
       "      <td>.</td>\n",
       "      <td>\\n\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0        1        2      3          4          5      6      7  \\\n",
       "0        xxbos       \\n    xxmaj     in       this   notebook      ,     we   \n",
       "1  classifying    movie  reviews     we    studied         in   part      1   \n",
       "2           \\n    xxmaj    first     we       will       look     at    the   \n",
       "3      numbers      and      how     to  customize         it      .  xxmaj   \n",
       "4      another  example       of    the      xxmaj  processor   used     in   \n",
       "5         then       we     will  study        how         we  build      a   \n",
       "\n",
       "            8      9         10     11       12       13     14  \n",
       "0        will     go       back   over      the  example     of  \n",
       "1         and    dig     deeper  under      the  surface      .  \n",
       "2  processing  steps  necessary     to  convert     text   into  \n",
       "3          by  doing       this      ,       we      'll   have  \n",
       "4         the   data      block    api        .       \\n  xxmaj  \n",
       "5    language  model        and  train       it        .   \\n\\n  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also view the data frame like this:\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting each batch of 15 tokens into 3 sub-batches of 5 tokens each can be done like this\n",
    "Here, `bptt` means `back-propagation through time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>xxbos</td>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>in</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>classifying</td>\n",
       "      <td>movie</td>\n",
       "      <td>reviews</td>\n",
       "      <td>we</td>\n",
       "      <td>studied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>first</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>numbers</td>\n",
       "      <td>and</td>\n",
       "      <td>how</td>\n",
       "      <td>to</td>\n",
       "      <td>customize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>another</td>\n",
       "      <td>example</td>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>then</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>study</td>\n",
       "      <td>how</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0        1        2      3          4\n",
       "0        xxbos       \\n    xxmaj     in       this\n",
       "1  classifying    movie  reviews     we    studied\n",
       "2           \\n    xxmaj    first     we       will\n",
       "3      numbers      and      how     to  customize\n",
       "4      another  example       of    the      xxmaj\n",
       "5         then       we     will  study        how"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>notebook</td>\n",
       "      <td>,</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>part</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>dig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>look</td>\n",
       "      <td>at</td>\n",
       "      <td>the</td>\n",
       "      <td>processing</td>\n",
       "      <td>steps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>it</td>\n",
       "      <td>.</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>by</td>\n",
       "      <td>doing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>processor</td>\n",
       "      <td>used</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>we</td>\n",
       "      <td>build</td>\n",
       "      <td>a</td>\n",
       "      <td>language</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2           3      4\n",
       "0   notebook      ,     we        will     go\n",
       "1         in   part      1         and    dig\n",
       "2       look     at    the  processing  steps\n",
       "3         it      .  xxmaj          by  doing\n",
       "4  processor   used     in         the   data\n",
       "5         we  build      a    language  model"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>back</td>\n",
       "      <td>over</td>\n",
       "      <td>the</td>\n",
       "      <td>example</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>deeper</td>\n",
       "      <td>under</td>\n",
       "      <td>the</td>\n",
       "      <td>surface</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>necessary</td>\n",
       "      <td>to</td>\n",
       "      <td>convert</td>\n",
       "      <td>text</td>\n",
       "      <td>into</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>this</td>\n",
       "      <td>,</td>\n",
       "      <td>we</td>\n",
       "      <td>'ll</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>block</td>\n",
       "      <td>api</td>\n",
       "      <td>.</td>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>and</td>\n",
       "      <td>train</td>\n",
       "      <td>it</td>\n",
       "      <td>.</td>\n",
       "      <td>\\n\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1        2        3      4\n",
       "0       back   over      the  example     of\n",
       "1     deeper  under      the  surface      .\n",
       "2  necessary     to  convert     text   into\n",
       "3       this      ,       we      'll   have\n",
       "4      block    api        .       \\n  xxmaj\n",
       "5        and  train       it        .   \\n\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_batches,bptt = 6,5\n",
    "for k in range(3):\n",
    "    d_tokens = np.array([tokens[i*seq_len + k*bptt:i*seq_len + (k+1)*bptt] for i in range(n_batches)])\n",
    "    df = pd.DataFrame(d_tokens)\n",
    "    #display(HTML(df.to_html(index=False,header=None)))\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LM_PreLoader():\n",
    "    def __init__(self, data, bs=64, bptt=70, shuffle=False):\n",
    "        self.data,self.bs,self.bptt,self.shuffle = data,bs,bptt,shuffle\n",
    "        total_len = sum([len(t) for t in data.x])\n",
    "        self.n_batch = total_len // bs\n",
    "        self.batchify()\n",
    "    \n",
    "    def __len__(self): return ((self.n_batch-1) // self.bptt) * self.bs\n",
    "    \n",
    "    def batchify(self):\n",
    "        texts = self.data.x\n",
    "        if self.shuffle: texts = texts[torch.randperm(len(texts))]\n",
    "        stream = torch.cat([tensor(t) for t in texts])\n",
    "        self.batched_data = stream[:self.n_batch * self.bs].view(self.bs, self.n_batch)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        source = self.batched_data[idx % self.bs] # % is the mod() operation\n",
    "        seq_idx = (idx // self.bs) * self.bptt\n",
    "        return source[seq_idx:seq_idx+self.bptt],source[seq_idx+1:seq_idx+self.bptt+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate a text DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(LM_PreLoader(ll.valid, shuffle=True), batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check it all works ok: `x1`, `y1`, `x2` and `y2` should all be of size `bs`  by `bptt`. The texts in each row of `x1` should continue in `x2`. `y1` and `y2` should have the same texts as their `x` counterpart, shifted of one position to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_dl = iter(dl)\n",
    "x1,y1 = next(iter_dl)\n",
    "x2,y2 = next(iter_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 70]), torch.Size([64, 70]))"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.size(),y1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = proc_num.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj saw this in a near empty cinema when it came out and enjoyed it all the more . xxmaj got it again on a battered old vhs and it is still as great . xxmaj so why do some people hate it ? i think firstly the film is more about mood than plot , so you have to be able to relax to get into it .'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(vocab[o] for o in x1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxmaj saw this in a near empty cinema when it came out and enjoyed it all the more . xxmaj got it again on a battered old vhs and it is still as great . xxmaj so why do some people hate it ? i think firstly the film is more about mood than plot , so you have to be able to relax to get into it . xxmaj'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(vocab[o] for o in y1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxmaj its dream - like and as in dreams ( and musicals ) not everything makes sense or looks right . xxmaj the film is also about colour , every set piece has been designed to show bright neon colours - again dream like , but to others it just looks fake . xxmaj and to top it all you have a dream girl in the shape of xxmaj natassia'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(vocab[o] for o in x2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's prepare some convenience function to do this quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_lm_dls(train_ds, valid_ds, bs, bptt, **kwargs):\n",
    "    return (DataLoader(LM_PreLoader(train_ds, bs, bptt, shuffle=True), batch_size=bs, **kwargs),\n",
    "            DataLoader(LM_PreLoader(valid_ds, bs, bptt, shuffle=False), batch_size=2*bs, **kwargs))\n",
    "\n",
    "def lm_databunchify(sd, bs, bptt, **kwargs):\n",
    "    return DataBunch(*get_lm_dls(sd.train, sd.valid, bs, bptt, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,bptt = 64,70\n",
    "data = lm_databunchify(ll, bs, bptt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we will want to tackle classification, gathering the data will be a bit different: first we will label our texts with the folder they come from, and then we will need to apply padding to batch them together. To avoid mixing very long texts with very short ones, we will also use `Sampler` to sort (with a bit of randomness for the training set) our samples by length.\n",
    "\n",
    "First the data block API calls shold look familiar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 12 video](https://course.fast.ai/videos/?lesson=12&t=5877)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_cat = CategoryProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='13' class='' max='13', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [13/13 02:32<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='13' class='' max='13', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [13/13 02:27<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "il = TextList.from_files(path, include=['train', 'test'])\n",
    "sd = SplitData.split_by_func(il, partial(grandparent_splitter, valid_name='test'))\n",
    "ll = label_by_func(sd, parent_labeler, proc_x = [proc_tok, proc_num], proc_y=proc_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SplitData\n",
       "Train: LabeledData\n",
       "x: TextList (25000 items)\n",
       "[[2, 7, 81, 13, 12, 145, 49, 61, 6926, 1419, 28, 12, 4396, 9, 7, 527, 60, 27, 12, 649, 150, 20, 15, 12, 1353, 509, 13, 1903, 223, 9, 12, 10940, 7256, 329, 15, 660, 104, 48, 2019, 10, 1069, 2495, 47, 8, 949, 0, 13, 16, 22, 5787, 9, 7, 494, 16, 2937, 1903, 8, 241, 75, 27, 74, 765, 1444, 872, 254, 16, 56, 117, 142, 1508, 9, 7, 76, 165, 51, 8, 958, 156, 43, 660, 142, 9, 7, 8, 12909, 430, 73, 113, 7, 2250, 327, 756, 14, 12, 846, 12352, 9, 7, 34, 12, 1919, 646, 16, 22, 146, 93, 32, 252, 122, 27, 65, 67, 665, 47, 714, 101, 7, 37310, 7, 39074, 9, 7, 714, 425, 7, 3582, 7, 21255, 11, 7, 11996, 7, 6461, 78, 43, 130, 3384, 9, 3], [2, 7, 4118, 62, 12233, 527, 26, 12, 3399, 183, 8685, 14591, 1595, 15, 4820, 72, 27, 4491, 6380, 200, 161, 11736, 14, 970, 4943, 7, 3759, 7, 4585, 36, 7, 619, 7, 1834, 33, 49, 15, 1701, 111, 200, 12, 760, 13, 24171, 22, 14, 40, 3820, 17, 9541, 13, 16, 129, 3200, 14, 8, 1041, 26, 12, 4756, 10, 103, 34, 1816, 15, 7, 4585, 544, 7, 1962, 36, 7, 7363, 7, 34698, 33, 200, 57, 480, 9, 7, 8, 8685, 59672, 326, 142, 26, 3629, 30, 2281, 23, 912, 8, 1595, 15, 5298, 23, 20172, 47, 8, 1126, 23, 1716, 7, 13099, 36, 7, 607, 7, 44838, 33, 200, 40, 127, 11240, 22, 7, 12566, 36, 7, 13657, 7, 22868, 33, 200, 7, 2383, 36, 7, 531, 7, 32871, 33, 49, 3328, 8, 5321, 200, 888, 60, 27, 2955, 2442, 10, 46, 1311, 14, 2165, 8, 4491, 10095, 200, 1290, 34, 12, 30076, 1595, 3282, 34, 48, 3822, 938, 30, 153, 254, 40, 5277, 7, 13099, 239, 1807, 48, 2838, 11743, 17, 8, 7, 3325, 200, 2120, 1138, 13, 8, 1595, 5041, 16, 6553, 104, 8, 1615, 135, 16, 8182, 14, 8, 1370, 228, 3973, 17, 8, 672, 13, 8, 7, 21262, 7, 4588, 9, 7, 27, 912, 17, 362, 5529, 10, 1000, 25611, 17, 200, 280, 15174, 143, 6269, 2338, 142, 286, 8, 705, 11279, 28, 8, 4777, 22, 26, 46, 11781, 364, 27, 75, 718, 641, 60, 92, 24, 7, 103, 559, 470, 8, 1067, 285, 26223, 7, 4118, 6051, 19, 347, 702, 14, 8, 6500, 23, 618, 1486, 698, 7, 4118, 36, 2760, 33, 25, 537, 47, 7, 1724, 7, 17027, 200, 153, 301, 193, 53, 16, 22, 8817, 18, 197, 35, 157, 7, 4118, 62, 12233, 15, 120, 454, 13, 1533, 391, 16, 15, 438, 284, 37, 2780, 28, 8, 228, 1014, 9, 7, 60, 13, 8, 298, 7, 4118, 125, 18, 41, 130, 52, 248, 18, 177, 447, 19, 42, 8, 139, 10, 56, 9, 7, 16, 61, 77, 1679, 131, 13, 8, 298, 27, 12, 358, 2281, 23, 912, 5298, 23, 30481, 200, 115, 8, 6553, 36, 87, 35, 39, 84, 8, 2838, 11743, 66, 33, 200, 6831, 13, 8, 14591, 36, 293, 8, 1207, 86, 282, 14, 1509, 8, 230, 7, 4118, 27, 176, 1099, 1486, 507, 13, 8, 827, 7, 8, 7, 17205, 7, 1152, 36, 5069, 33, 33, 200, 17209, 15, 135, 16, 2937, 385, 8, 149, 27, 12, 4557, 5775, 4310, 165, 2391, 977, 10, 371, 43911, 68, 8, 912, 1151, 60, 55, 10974, 26, 8, 14591, 21892, 55, 63, 120, 13, 8, 3802, 38, 3200, 200, 16, 22, 12, 549, 338, 20, 95, 41, 112, 28, 12, 101, 138, 1486, 507, 30, 97, 7068, 123, 22, 10, 782, 430, 10, 13464, 289, 23, 1314, 200, 12, 164, 623, 13, 2368, 55, 796, 55, 1131, 812, 19, 15, 12, 1124, 1433, 9, 7, 153, 8, 269, 10997, 131, 948, 42, 2456, 28, 22257, 1054, 247, 37, 20, 94, 575, 119, 8, 1595, 8182, 200, 54, 22, 37, 26, 94, 11492, 26, 18, 217, 54, 156, 41, 99, 9, 7, 76, 68, 8, 7, 3517, 446, 584, 198, 58, 35, 1205, 72, 20, 94, 27, 12, 190, 692, 13, 678, 4726, 200, 10094, 1701, 59, 30, 54, 22, 56, 158, 1832, 148, 9, 7, 732, 7, 3006, 26, 8, 55825, 13851, 3691, 7, 913, 7, 32837, 15, 162, 30, 82, 240, 12, 384, 13, 155, 200, 1189, 76, 566, 255, 14767, 14, 56, 185, 3748, 17, 8, 953, 9, 24, 7, 8, 363, 397, 200, 2282, 349, 13, 7, 4118, 62, 12233, 505, 22257, 247, 153, 8, 202, 263, 2487, 719, 48, 1536, 563, 13, 898, 592, 12, 183, 649, 910, 725, 10, 128, 69, 155, 27, 7, 732, 7, 3006, 26, 7, 32837, 10, 2108, 14, 2092, 60, 123, 22, 10, 1135, 2073, 155, 200, 8, 3697, 55, 176, 384, 13, 352, 2103, 592, 8, 22848, 9, 7, 153, 18, 73, 53, 14, 84, 19, 1536, 898, 18, 256, 37, 273, 18, 95, 873, 163, 12, 748, 298, 563, 609, 13, 7, 4118, 62, 12233, 9, 7, 26, 862, 8, 31, 61, 1967, 959, 27, 506, 8278, 200, 6586, 1710, 2621, 10, 18, 105, 157, 74, 69, 102, 93, 8, 3127, 1595, 2158, 303, 38, 35, 101, 371, 9, 7, 359, 27, 8, 102, 127, 7, 4118, 2003, 19, 326, 3490, 13, 287, 17, 8, 7, 11385, 7, 1460, 22, 7, 2284, 13, 7, 904, 284, 18, 78, 122, 13, 746, 13, 457, 125, 93, 19, 52, 18, 10950, 20, 22, 12, 138, 2657, 9, 7, 8, 212, 155, 38, 12, 138, 782, 494, 10, 8, 1074, 15, 577, 200, 37, 94, 2353, 55, 1131, 15, 4945, 79, 15, 12, 904, 26, 18, 10950, 19, 95, 41, 99, 12, 206, 67, 31, 63, 112, 2834, 9, 24, 7, 8, 389, 1188, 38, 2823, 63, 181, 2174, 9, 7, 8, 137, 15, 35, 101, 10, 127, 75, 7, 853, 2320, 7, 690, 7, 4925, 61, 322, 251, 16, 25, 12, 1439, 14, 337, 17, 19, 10, 42, 75, 7, 853, 2320, 7, 619, 7, 1834, 309, 175, 200, 12584, 10, 103, 42, 75, 7, 853, 2320, 7, 863, 7, 1666, 309, 1958, 153, 7, 2673, 7, 1523, 7, 863, 15, 388, 138, 14, 58, 200, 54, 38, 984, 13, 102, 1083, 1448, 14, 185, 60, 28, 117, 9, 24, 7, 4118, 62, 12233, 15, 8, 110, 1486, 19144, 13, 8, 298, 7, 4118, 125, 52, 248, 200, 18, 447, 8, 1017, 535, 16, 76, 63, 46, 86, 12, 244, 667, 10, 8, 389, 200, 2028, 471, 91, 35, 364, 174, 200, 12, 31, 59, 12, 18684, 1595, 56, 156, 35, 43, 19, 368, 55, 13464, 9, 7, 1623, 47, 7, 8, 7, 12823, 92, 7, 4118, 62, 14015, 36, 5000, 33, 9, 3], [2, 7, 19, 31, 3584, 158, 18, 95, 35, 300, 77, 3725, 34, 45, 107, 96, 3227, 34, 8, 192, 13, 8, 997, 556, 9, 7, 19, 5372, 5824, 14, 623, 13, 1208, 68, 71, 5457, 8, 279, 27, 57, 997, 145, 9, 7, 76, 8, 742, 155, 404, 621, 26, 129, 1543, 8, 171, 45, 320, 9, 7, 16, 95, 70, 89, 41, 99, 8, 170, 49, 37017, 64, 39, 919, 51, 8, 171, 9, 18, 56, 58, 35, 140, 9, 24, 7, 30, 95, 16, 41, 99, 8, 917, 66, 7, 56, 630, 49, 25, 8, 7189, 17, 134, 27, 66, 7, 39, 478, 69, 15788, 13, 40, 30763, 1929, 11, 3185, 10, 11, 1127, 13, 333, 11, 40, 6492, 6291, 10, 93, 13, 1819, 55, 255, 345, 9, 7, 39, 132, 2538, 88, 39, 25, 17, 134, 27, 8, 2642, 9, 24, 18, 25, 684, 17, 19, 29, 9, 7, 30, 10, 58, 35, 849, 16, 25, 2485, 28, 48, 7, 853, 10, 52, 1646, 28, 668, 9, 3], [2, 7, 772, 310, 10, 10, 10, 18, 140, 19, 15, 460, 14, 43, 48, 21, 552, 21, 31, 10, 10, 30, 1380, 10, 46, 156, 41, 2703, 60, 1840, 45, 8, 2655, 52, 100, 95, 2212, 80, 3875, 60, 11, 37, 126, 9, 7, 284, 8, 150, 1710, 11, 13671, 471, 25, 342, 10, 19, 81, 15, 117, 1356, 14, 126, 9, 7, 8, 3960, 13, 12, 497, 1420, 25, 1781, 9, 7, 8, 5003, 4, 224, 1438, 4, 373, 2778, 3064, 692, 86, 117, 214, 9, 7, 109, 214, 78, 32, 126, 127, 100, 56, 1333, 54, 11, 696, 66, 7, 278, 68, 8, 430, 15, 127, 100, 5060, 9, 18, 83, 85, 12, 266, 75, 56, 405, 163, 19, 31, 9, 7, 8, 374, 86, 342, 10, 30, 109, 94, 13, 20, 475, 10, 15555, 10, 3341, 10, 539, 78, 32, 213, 66, 7, 8, 82, 169, 18, 447, 25, 7, 8124, 7, 17648, 11, 57, 806, 2431, 11, 1234, 150, 9, 7, 885, 19, 25, 12, 6851, 13, 7, 3309, 9, 7, 11, 18, 167, 74, 354, 2276, 40, 371, 9, 18, 122, 270, 49, 566, 46, 521, 382, 382, 124, 264, 615, 13, 19, 15, 10, 10, 89, 10, 3257, 9, 3], [2, 7, 68, 18, 25, 138, 77, 722, 572, 88, 359, 14, 8, 803, 14, 84, 7, 9066, 9, 7, 16, 25, 42, 13, 128, 118, 18, 321, 27, 77, 722, 10, 30, 19, 25, 8, 82, 42, 90, 2382, 60, 13, 9, 7, 251, 115, 18, 85, 132, 130, 7, 9066, 385, 56, 1053, 10, 11, 18, 95, 41, 1411, 60, 8, 396, 13, 77, 136, 229, 16, 9, 7, 64, 12, 2144, 10, 12356, 10, 11, 2283, 368, 453, 13, 1355, 22, 4717, 11, 2830, 4716, 9, 7, 2230, 7, 1463, 15, 42, 13, 77, 540, 998, 30, 7, 9066, 15, 47, 248, 8, 271, 453, 13, 626, 13, 40, 625, 9, 7, 17, 8, 15423, 418, 13, 7, 12412, 7, 23884, 10, 7, 1463, 427, 202, 12, 475, 10, 25613, 10, 10632, 10, 2646, 17, 14, 8, 481, 13, 12, 253, 13101, 47, 8, 1991, 4201, 2364, 47, 4020, 10, 30860, 10, 625, 10, 134, 10, 700, 23, 134, 10, 0, 10, 845, 9, 7, 8, 31, 10, 5259, 10, 61, 74, 721, 2055, 10, 74, 238, 10, 11, 15, 13492, 17, 10313, 6107, 9, 7, 19, 31, 418, 78, 43, 139, 4785, 26, 16676, 17, 965, 10, 801, 48, 22149, 4090, 13, 430, 14, 15001, 12, 21, 69, 11329, 1139, 13, 1193, 11, 829, 21, 9, 7, 30, 7, 2230, 7, 1463, 15, 74, 7, 12412, 7, 3309, 9, 7, 8, 31, 15, 2283, 577, 11, 782, 9, 7, 30, 694, 20, 10, 18, 350, 85, 74, 1974, 27, 55, 2465, 28, 120, 13, 8, 121, 9, 7, 319, 18, 468, 82, 7081, 28, 19, 5676, 13, 20792, 10, 7135, 10, 29531, 14282, 10, 33494, 17, 12, 12001, 2897, 28, 1947, 9, 7, 8256, 12, 3596, 13, 21561, 41130, 11, 7765, 7, 31571, 42044, 8, 81, 20451, 53, 12, 6985, 17, 8, 679, 9, 7, 310, 2419, 17, 4085, 20278, 11, 11296, 1078, 222, 7908, 9, 7, 310, 15, 21, 437, 21, 11, 21, 2781, 21, 10, 1845, 14, 186, 471, 55, 1746, 55, 845, 11, 16, 56, 291, 34, 11, 34, 14, 8, 243, 135, 32, 56, 204, 14, 4190, 44, 13, 111, 9, 7, 16, 22, 132, 59, 3869, 10, 16, 22, 82, 59, 11582, 14200, 14968, 9, 7, 16, 15, 181, 69, 93, 12, 1991, 459, 603, 14, 48, 1570, 694, 8, 329, 22, 1244, 14, 3931, 9, 7, 2230, 7, 1463, 2717, 14, 113, 121, 52, 11336, 17, 528, 90, 250, 336, 60, 9, 7, 11, 28, 20, 312, 18, 274, 19, 29, 2283, 553, 5023, 11, 16010, 17450, 9, 18, 84, 64, 39, 25, 184, 28, 30, 40, 12689, 34, 9385, 40, 766, 163, 7, 23303, 15367, 11, 8159, 31, 3218, 42323, 16, 520, 8, 243, 13, 6747, 9, 18, 567, 407, 19, 42, 63, 32, 199, 574, 12, 138, 117, 666, 11, 387, 158, 14, 3115, 32, 13, 340, 9, 7, 885, 10, 306, 22, 56, 3795, 19, 31, 132, 582, 9, 3], [2, 21, 7, 16, 738, 20, 128, 1470, 186, 8, 338, 13, 12, 7, 2230, 7, 1463, 459, 37900, 9, 21, 7, 11, 28, 67, 312, 96, 46, 38, 10691, 1681, 11, 2144, 14012, 13, 7, 3309, 9, 7, 11, 306, 22, 37, 543, 3326, 96, 1470, 86, 676, 8357, 13, 7, 1463, 22, 7, 3309, 11052, 10, 7, 1463, 22, 7135, 13126, 14, 8, 3947, 10016, 9, 7, 64, 18, 58, 35, 98, 15, 19, 96, 154, 25, 7, 1463, 1268, 11597, 28, 40, 2660, 17, 9348, 7, 3309, 10, 30, 8, 31806, 7, 1961, 13623, 25, 0, 28, 21, 5637, 142, 21, 7, 1477, 17, 40, 796, 124, 201, 125, 66, 7, 17, 7, 1532, 7, 1744, 22, 673, 10, 16, 22, 12, 675, 824, 13, 2776, 23658, 9, 18, 73, 41, 14, 1047, 27, 20, 9, 3], [2, 7, 8, 347, 593, 47, 12, 7, 183, 7, 786, 2940, 17, 361, 93, 182, 173, 14, 113, 12, 21, 7, 3639, 21, 31, 23, 8, 107, 129, 7, 2537, 7, 0, 22, 21, 7, 627, 7, 3923, 21, 36, 79, 25, 112, 17, 7, 7417, 10, 27, 7, 3639, 171, 10, 74, 361, 50, 33, 7, 8, 1934, 66, 7, 853, 7, 9445, 322, 16, 139, 10, 17, 2734, 14, 7, 6130, 62, 21, 7, 8, 7, 175, 7, 3312, 7, 2026, 21, 96, 21, 7, 42, 73, 41, 14, 41, 12, 504, 13, 1562, 37, 14, 448, 60, 1352, 45, 8, 340, 13, 7, 138, 7, 11700, 9, 21, 7, 206, 94, 8, 187, 169, 148, 9, 21, 7, 9066, 21, 15, 9219, 390, 13, 31487, 0, 22776, 9, 36, 21, 18, 167, 1674, 13, 77, 2700, 9, 21, 7, 281, 104, 8, 672, 3834, 96, 21, 18, 58, 35, 53, 49, 18, 167, 1545, 9, 21, 33, 7, 8, 3672, 27388, 36, 14, 380, 12, 9616, 2586, 33, 51, 7, 3309, 38, 519, 14, 1940, 9, 7, 8, 973, 553, 23, 584, 253, 409, 7204, 202, 13, 109, 548, 11, 1042, 46, 38, 10, 14, 8, 243, 13, 21752, 9, 36, 21, 18, 370, 12, 5772, 13, 6803, 8, 102, 272, 9, 7, 16, 25, 17, 23, 18, 58, 35, 140, 23, 7, 8, 7, 183, 7, 12766, 9, 21, 21, 7, 451, 9, 7, 20, 25, 48, 175, 5772, 9, 18, 18563, 16, 9, 21, 33, 7, 248, 51, 37, 3143, 59, 151, 100, 10, 216, 10, 18, 274, 111, 203, 610, 9, 7, 94, 13, 8, 734, 15, 630, 53, 8, 172, 539, 51, 7, 1463, 22, 930, 125, 23, 82, 39, 22, 537, 40, 171, 14, 320, 8, 429, 712, 9, 7, 280, 37, 196, 333, 17, 8, 29, 10, 39, 61, 357, 7, 1156, 7, 6412, 7, 1512, 986, 44, 13, 40, 12763, 22082, 10, 37306, 10, 11, 5703, 9612, 10, 1618, 57, 104, 48, 2235, 13925, 36, 94, 53, 7, 5660, 7, 5720, 17, 21, 7, 4270, 21, 33, 9, 24, 7, 8, 1154, 131, 23, 5516, 253, 27, 5144, 14458, 403, 23, 208, 14, 43, 5054, 69, 55, 361, 51, 7, 3309, 22, 21, 7, 3889, 7, 648, 10, 21, 8, 1154, 253, 2552, 9304, 72, 27, 12, 188, 13, 8642, 4704, 9, 7, 16, 44, 297, 163, 17, 8, 35732, 1121, 124, 20316, 3214, 96, 8, 25233, 7275, 13, 12, 13089, 34, 2017, 10, 8, 12507, 6833, 20, 10889, 8, 100, 1361, 34, 8, 1916, 9, 538, 10, 538, 9, 24, 7, 1463, 22, 328, 21, 624, 21, 125, 38, 361, 2235, 10, 30, 103, 248, 361, 438, 9, 18, 259, 213, 21, 7, 9066, 9, 21, 7, 2230, 22, 1683, 112, 12, 2632, 29, 9, 3], [2, 18, 58, 35, 140, 49, 14, 1690, 10, 8, 11119, 942, 55, 8, 4936, 170, 9, 7, 16, 478, 14, 43, 42, 13, 165, 118, 135, 52, 94, 25, 1520, 14, 8, 425, 36, 7, 8386, 10, 7, 1211, 10, 7, 9411, 10, 7, 13452, 11, 7, 3669, 33, 20, 54, 25, 35, 215, 336, 14, 83, 113, 12, 29, 9, 7, 19, 95, 41, 99, 70, 438, 10, 30, 54, 25, 12, 14067, 13, 41265, 10, 76, 18496, 10, 20, 5170, 143, 276, 150, 9, 7, 251, 16, 207, 48, 2109, 707, 578, 154, 25, 8, 11353, 7782, 5052, 150, 339, 27, 12, 55826, 23, 175, 267, 11, 37, 7, 8386, 7, 12835, 66, 7, 154, 91, 7, 5018, 21368, 163, 4054, 891, 1488, 27, 127, 13, 8, 110, 343, 11, 1251, 1432, 17, 8, 195, 66, 7, 63, 46, 86, 82, 281, 28, 932, 154, 37, 196, 7, 9322, 7, 5837, 11, 7, 4296, 7, 55827, 319, 66, 7, 19, 25, 52, 740, 18, 25, 774, 14, 186, 20, 8, 170, 25, 35, 12, 750, 341, 175, 9, 7, 64, 12, 473, 10, 37, 56, 28, 8, 798, 30, 28, 8, 171, 26, 89, 9, 3], [2, 7, 19, 31, 15, 1557, 45, 139, 9, 7, 8386, 7, 12835, 15, 26, 172, 26, 12, 2942, 13, 22378, 9, 7, 57, 8114, 8531, 51, 21, 7, 1141, 11, 7, 652, 21, 2777, 143, 17, 12, 1232, 593, 45, 223, 9, 7, 1211, 7, 5018, 15, 8, 82, 42, 14, 234, 60, 14849, 17, 19, 506, 1190, 23, 223, 9, 7, 8, 82, 1203, 169, 14, 234, 60, 13, 19, 946, 15, 7, 1211, 11, 7, 9411, 22, 1413, 9, 7, 2216, 20, 794, 6338, 146, 1934, 9, 3], [2, 7, 8, 31, 15, 97, 9, 7, 54, 15, 74, 102, 116, 14, 157, 16, 9, 7, 8, 81, 15, 871, 11, 6695, 10, 278, 28, 19, 671, 9, 18, 58, 35, 122, 110, 100, 140, 64, 12, 21, 3322, 21, 15, 55, 105, 83, 474, 9, 18, 468, 26, 63, 18, 25, 168, 12, 29, 51, 8, 1355, 22, 9, 7, 8, 865, 25, 56, 37, 834, 28, 8, 341, 4187, 10, 76, 129, 289, 17, 9320, 9, 18, 122, 19, 13352, 313, 28, 310, 345, 49, 321, 16, 117, 26, 8, 8520, 86, 378, 11, 1554, 45, 8, 149, 9, 7, 110, 87, 35, 789, 28, 8, 12732, 371, 9, 24, 18, 58, 35, 122, 7, 14645, 83, 217, 8, 31, 60, 1425, 13, 75, 9, 7, 128, 13, 8, 155, 478, 14, 43, 609, 362, 26, 63, 46, 86, 132, 1810, 55, 39, 56, 87, 35, 140, 109, 14, 1421, 111, 9, 7, 39, 5320, 51, 42, 150, 14, 8, 383, 11, 32, 85, 14, 377, 11, 864, 60, 55, 489, 64, 25, 184, 34, 9, 18, 83, 87, 35, 98, 7, 2230, 22, 36, 7, 3296, 33, 1976, 136, 55, 1381, 371, 9, 7, 64, 86, 44, 8, 21, 1759, 21, 896, 9501, 11, 1738, 1332, 36, 51, 7, 4352, 12207, 33, 59, 66, 7, 64, 25, 39, 555, 66, 18, 122, 16, 25, 40, 70, 357, 593, 45, 282, 14, 1034, 19, 475, 1976, 18702, 136, 28, 7, 2230, 22, 123, 36, 7, 529, 33, 9, 7, 16, 87, 35, 180, 9, 7, 16, 87, 35, 76, 327, 14, 113, 292, 83, 9, 24, 7, 8, 82, 67, 169, 59, 19, 31, 25, 7, 2230, 7, 11024, 9, 7, 39, 275, 40, 123, 36, 7, 529, 33, 13151, 9, 7, 32, 83, 87, 98, 12, 101, 292, 13, 64, 12, 21, 3322, 21, 227, 41, 99, 53, 36, 157, 1712, 173, 617, 33, 9, 7, 39, 25, 101, 11, 110, 1297, 105, 132, 98, 4219, 28, 16, 9, 24, 7, 26, 28, 7, 5862, 10, 7, 5609, 11, 7, 9527, 92, 7, 368, 9, 24, 7, 58, 35, 84, 16, 50, 7, 16, 15, 1356, 50, 7, 933, 32, 38, 12, 313, 7, 11024, 354, 9, 3]...]\n",
       "Path: C:\\Users\\cross-entropy\\.fastai\\data\\imdb\n",
       "y: ItemList (25000 items)\n",
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0...]\n",
       "Path: C:\\Users\\cross-entropy\\.fastai\\data\\imdb\n",
       "\n",
       "Valid: LabeledData\n",
       "x: TextList (25000 items)\n",
       "[[2, 7, 301, 193, 7, 596, 7, 5444, 61, 3435, 60, 12, 29, 28, 248, 1135, 93, 1700, 9, 7, 1216, 51, 8, 1353, 1615, 2073, 828, 10, 13, 79, 54, 38, 70, 190, 18, 56, 87, 37, 474, 59, 120, 13, 8, 121, 9, 7, 110, 13, 202, 41, 3017, 17, 8, 4844, 10, 11, 7, 5444, 22, 123, 38, 1695, 432, 34, 10, 11, 115, 1533, 385, 94, 328, 10, 47, 79, 75, 18, 87, 37, 474, 9, 7, 8, 123, 90, 156, 83, 474, 59, 15, 12, 70, 9452, 10, 37895, 7, 8476, 7, 10744, 9, 7, 8, 462, 15, 39, 297, 142, 26, 543, 49, 1212, 39, 22, 146, 93, 270, 345, 209, 108, 11, 294, 74, 3670, 13, 12, 16872, 4844, 9, 7, 40, 82, 13455, 738, 14, 43, 1769, 143, 7, 5444, 9, 7, 449, 68, 90, 38, 89, 520, 8, 331, 116, 243, 13, 19, 3972, 10, 7, 5444, 715, 202, 44, 59, 7, 10744, 22, 3017, 9, 7, 90, 38, 594, 154, 7, 10744, 15, 2084, 14, 43, 8, 139, 27, 74, 2716, 16667, 55, 12049, 9, 7, 74, 1298, 148, 10, 16, 25, 44, 18, 95, 58, 14, 409, 51, 1618, 16, 142, 48, 563, 17, 9, 3], [2, 7, 19, 15, 48, 509, 13, 154, 8, 2163, 13, 212, 125, 38, 8, 187, 9, 7, 3799, 11, 368, 10, 54, 22, 83, 181, 295, 168, 148, 9, 12, 622, 473, 13, 8, 115, 1189, 23, 15267, 2014, 13, 7, 1775, 23, 2326, 11, 7, 1775, 7, 5567, 10, 49, 160, 276, 14083, 128, 235, 143, 20, 46, 38, 2114, 13, 137, 10, 11, 137, 89, 9, 7, 58, 35, 1326, 27, 19, 42, 10, 159, 84, 7, 183, 7, 690, 7, 513, 10, 7, 36173, 55, 126, 7, 183, 7, 786, 7, 5201, 28, 7, 1775, 23, 2326, 10, 55, 7, 16480, 2778, 8, 7, 2605, 10, 7, 2024, 7, 2795, 55, 7, 2195, 28, 7, 1775, 7, 5567, 11, 84, 8, 164, 833, 9, 7, 1775, 23, 2326, 22, 2215, 7148, 430, 640, 179, 19, 31, 17080, 45, 8, 2879, 10, 11, 18, 167, 152, 1583, 64, 8, 2132, 7, 963, 7, 7543, 25, 422, 17, 19, 31, 66, 7, 11, 154, 8, 2132, 91, 39, 237, 320, 8, 2496, 187, 123, 66, 7, 51, 7, 1663, 19107, 10, 191, 31, 18, 160, 130, 27, 7, 963, 7, 7543, 61, 108, 417, 8, 2496, 187, 2167, 123, 10, 11, 45, 242, 17, 7, 1663, 40, 123, 1095, 10, 79, 112, 16, 664, 17312, 92, 24, 7, 463, 10, 19, 15, 347, 23, 999, 212, 1238, 9, 7, 54, 38, 3415, 146, 125, 14, 84, 10, 11, 63, 32, 83, 204, 14, 84, 19, 42, 10, 126, 7, 8995, 7, 330, 10, 79, 15, 2342, 12, 12157, 986, 30, 61, 146, 137, 11, 12, 146, 246, 9, 7, 8, 82, 169, 20, 112, 19, 45, 44, 295, 168, 25, 12, 549, 517, 34, 8, 376, 23, 8, 665, 25, 239, 2337, 10, 79, 297, 519, 14, 254, 72, 28, 8, 506, 31, 414, 23, 30, 37, 203, 9, 224, 124, 182, 9, 3], [2, 7, 107, 13, 44, 18, 741, 165, 5238, 13334, 10, 49, 30074, 512, 63, 46, 85, 12, 924, 6898, 467, 80, 31097, 9, 7, 44, 46, 58, 15, 2687, 11, 1197, 276, 102, 11, 137, 53, 0, 349, 13, 3917, 9, 24, 7, 8, 29, 91, 35, 213, 69, 93, 750, 247, 14, 1267, 64, 15, 184, 34, 178, 90, 199, 492, 45, 8, 7625, 7, 54, 15, 37, 12, 693, 2176, 123, 17, 19, 29, 10, 565, 28, 8, 4601, 231, 10, 49, 15, 103, 8, 82, 42, 27, 331, 12, 1186, 9, 24, 7, 963, 7, 7543, 11, 7, 988, 7, 20927, 38, 218, 2154, 52536, 11, 7, 0, 123, 15, 56, 26, 94, 12, 1006, 26, 8, 3917, 9, 18, 20928, 53, 108, 228, 51, 8, 392, 9, 24, 7, 8, 29, 15, 1063, 27, 1118, 564, 11, 7, 2662, 7, 3170, 15772, 96, 100, 1500, 163, 5903, 27, 2914, 1701, 2519, 9, 7, 54, 15, 206, 94, 74, 131, 11, 16, 15, 12, 219, 462, 68, 32, 3870, 28, 74, 23, 42, 9, 7, 1278, 1468, 10, 565, 51, 7, 7543, 11, 8, 4601, 231, 11, 1278, 98, 64, 46, 1782, 9, 24, 7, 8, 82, 127, 334, 100, 20, 78, 512, 15, 8, 4601, 231, 11, 8, 7834, 30, 46, 199, 171, 47, 5742, 10, 37, 634, 1510, 1186, 352, 13334, 9, 24, 7, 789, 262, 51, 19, 626, 11, 126, 7987, 615, 382, 11, 264, 319, 9, 7, 45, 10460, 46, 41, 121, 32, 474, 59, 10, 12, 292, 13, 469, 11, 181, 30, 164, 171, 17, 8, 196, 9, 3], [2, 7, 37, 76, 8, 7, 4965, 95, 943, 778, 310, 447, 10, 11, 284, 7, 2662, 7, 2154, 15, 74, 26786, 23, 365, 39, 22, 347, 14, 620, 68, 16, 297, 14, 217, 2811, 212, 118, 9, 7, 8, 8639, 404, 11, 1111, 34684, 86, 2497, 17, 238, 11, 31, 10, 8, 18561, 13, 8, 7, 11428, 660, 29, 337, 25, 17, 390, 6689, 10, 8, 137, 572, 12, 162, 2000, 14, 276, 145, 22, 16286, 15268, 1225, 11, 8801, 137, 9, 7, 19, 25, 42, 13, 8, 128, 1775, 23, 2326, 118, 18, 233, 26, 12, 543, 11, 476, 10, 82, 14, 126, 111, 328, 11, 3348, 9, 7, 963, 7, 7543, 11, 7, 988, 7, 20927, 38, 17313, 27, 1154, 481, 385, 12, 3391, 1279, 9661, 59, 14, 159, 72, 17, 7790, 922, 143, 12, 5218, 27, 1608, 9453, 9, 18, 517, 16, 14, 7, 2662, 28, 941, 11, 6645, 937, 72, 8, 305, 121, 11, 1559, 9, 7, 30, 18, 2051, 310, 584, 28, 1618, 60, 7, 874, 23, 1438, 374, 9, 7, 1775, 23, 2326, 11, 5567, 225, 41, 99, 806, 891, 45, 19, 75, 10, 11, 153, 18, 160, 521, 218, 80, 3649, 26, 13334, 10, 17, 77, 683, 46, 1609, 1065, 17, 19, 29, 9, 7, 16, 22, 59, 7626, 247, 13, 42, 231, 3650, 1618, 40, 162, 34, 8, 102, 231, 14, 8, 243, 32, 186, 668, 3183, 17, 2628, 1568, 13, 2864, 9, 7, 166, 19, 15, 12, 29, 10, 114, 37, 12, 632, 52, 18, 491, 1146, 473, 77, 75, 17532, 44, 8, 394, 131, 1260, 17, 19, 29, 10, 30, 54, 86, 128, 10, 11, 46, 1610, 1265, 9, 18, 207, 8, 574, 168, 19, 20, 310, 34, 289, 25, 0, 13, 1489, 11, 56, 417, 198, 142, 8, 22504, 9, 7, 54, 38, 127, 198, 18, 152, 386, 59, 16, 10, 42, 2115, 12, 150, 27, 12, 11951, 11, 8, 102, 15, 7, 20927, 22, 678, 3806, 7208, 9, 7, 1370, 367, 19, 29, 15, 53, 9354, 22, 7007, 9, 7, 1167, 1944, 1876, 16, 63, 18, 167, 4995, 11, 18, 58, 35, 250, 53, 6690, 10, 7, 30, 18, 167, 89, 1854, 16, 4645, 53, 626, 9, 381, 425, 10, 19108, 9, 3], [2, 7, 8434, 1332, 36, 118, 15, 37, 12, 3731, 680, 28, 111, 33, 83, 38, 664, 22505, 9, 7, 80, 9355, 1121, 2334, 38, 2786, 13, 3336, 325, 729, 263, 3732, 9, 7, 30, 494, 7, 8434, 1332, 38, 821, 125, 27, 8, 11429, 13, 1675, 14, 2828, 798, 28, 143, 127, 615, 50, 7, 17, 19, 46, 1984, 3253, 10, 80, 9662, 10, 30, 269, 1813, 11, 22120, 93, 9143, 10, 2499, 2334, 700, 24973, 9, 24, 7, 48204, 62, 3806, 15, 12, 1008, 13, 12, 31, 47, 7, 19109, 7, 8838, 27, 8, 187, 441, 11, 7, 26157, 7, 20929, 11, 7, 6968, 7, 8517, 17, 8, 472, 9, 7, 8, 230, 715, 12, 81, 13, 4855, 134, 11, 3936, 17, 11, 209, 7, 6346, 316, 8, 7, 1057, 1575, 13, 6218, 9, 7, 8434, 1654, 8, 212, 51, 8, 4864, 104, 8, 3856, 1109, 10, 6691, 14, 43, 2496, 10, 52, 54, 38, 7, 15592, 58575, 10, 346, 17, 334, 7715, 10, 7, 1049, 6846, 55, 8, 19661, 16120, 13, 8, 20592, 9, 7, 30, 16, 15, 56, 1847, 5153, 10, 8, 5312, 1965, 15, 353, 19379, 9, 24, 7, 2081, 7, 0, 314, 8, 1587, 12050, 267, 49, 751, 28, 8, 9039, 8477, 231, 49, 237, 1394, 34, 117, 94, 10612, 9, 7, 71, 15, 48, 1587, 10, 8802, 10, 89, 4039, 7, 1057, 556, 11, 701, 730, 8, 847, 9, 7, 57, 1887, 2047, 13, 2933, 2925, 36, 58576, 3157, 10, 10678, 10, 2895, 10, 1117, 10, 741, 92, 11, 11952, 33, 38, 8, 139, 312, 14, 126, 19, 455, 11, 295, 127, 425, 9, 7, 71, 15269, 19, 681, 4500, 539, 27, 48, 4712, 1157, 13, 4100, 9, 18, 657, 65, 83, 67, 524, 234, 359, 28, 57, 9, 7, 71, 83, 1032, 16, 9, 3], [2, 12, 172, 169, 582, 14, 88, 153, 168, 21, 7, 23934, 21, 96, 34, 8, 42, 517, 10, 8, 576, 15, 12, 4950, 23, 4938, 11, 8, 170, 15, 479, 2074, 14, 113, 202, 408, 154, 39, 91, 64, 39, 91, 36, 22968, 13830, 92, 5755, 10, 1410, 88, 10, 4926, 33, 163, 40, 1209, 9, 7, 34, 8, 102, 517, 10, 8, 7, 644, 349, 45, 242, 15, 70, 959, 2330, 9, 7, 52, 18, 274, 560, 4888, 54, 85, 99, 218, 69, 11, 361, 430, 45, 8, 187, 75, 50, 7, 19, 31, 15, 394, 36, 172, 109, 19, 231, 61, 4951, 14, 191, 7928, 11, 20593, 17, 40, 501, 33, 11, 8887, 36, 135, 73, 90, 43, 17, 12, 1915, 44767, 229, 277, 2302, 2295, 150, 66, 33, 9, 7, 37, 14, 755, 8, 21, 742, 21, 1287, 36, 451, 10, 109, 0, 92, 7, 691, 16, 9, 36, 194, 33, 3], [2, 7, 19, 7, 1049, 201, 31, 61, 14, 43, 42, 13, 8, 12436, 18, 41, 130, 9, 24, 18, 25, 37, 1854, 13, 120, 1974, 222, 518, 2473, 11, 17533, 10, 30, 19, 15, 460, 452, 713, 12, 313, 123, 9, 24, 7, 277, 576, 15, 4950, 11, 4938, 26, 12, 929, 13, 2733, 14797, 45, 8, 922, 13, 40, 356, 9, 39, 103, 61, 12, 3222, 9083, 10, 30, 18, 78, 37, 864, 60, 135, 20, 404, 51, 9, 7, 40, 1126, 23, 3009, 186, 60, 11, 9555, 108, 1995, 9, 24, 7, 316, 8, 272, 12, 3662, 23, 1426, 12158, 10, 11, 45, 330, 39, 2036, 104, 37896, 11, 3504, 5904, 11, 5280, 8, 557, 13, 352, 546, 9, 7, 46, 38, 44, 1587, 10, 13, 286, 10, 345, 90, 73, 35, 474, 59, 8, 211, 20, 39, 638, 1711, 80, 4306, 205, 14, 8, 10461, 9, 7, 39, 15773, 872, 14, 177, 825, 10, 11, 20, 15, 64, 240, 108, 1021, 9, 24, 7, 53, 18, 322, 10, 12, 70, 675, 29, 20, 15, 475, 11, 70, 577, 26, 7, 10279, 7, 48205, 132, 2160, 11, 56, 2395, 40, 75, 2506, 557, 9, 3], [2, 7, 129, 12, 214, 23, 75, 354, 13, 7, 980, 31, 10, 18, 862, 69, 93, 19, 9, 18, 197, 35, 83, 43, 2525, 14, 943, 14, 94, 10, 26, 19, 29, 15, 56, 52, 357, 9, 7, 8, 81, 252, 43, 8, 16668, 742, 138, 158, 144, 10, 2312, 18, 95, 35, 771, 8, 398, 137, 10, 8, 946, 46, 461, 1796, 10, 11, 8, 1220, 21, 2507, 21, 7, 980, 81, 9, 7, 63, 32, 160, 1957, 109, 128, 7, 980, 118, 380, 121, 10, 1638, 11, 1260, 20, 327, 117, 21, 285, 21, 10, 0, 52, 10, 115, 5850, 736, 13, 19, 29, 9, 7, 637, 10, 12, 14798, 175, 95, 41, 594, 32, 109, 19, 29, 25, 184, 14, 837, 359, 10, 11, 20, 22, 37, 12, 67, 169, 17, 77, 308, 9, 24, 7, 466, 13, 21, 7, 1495, 21, 7, 13688, 96, 40, 192, 17, 19, 29, 15, 37, 83, 69, 93, 12, 2010, 10, 11, 933, 32, 199, 12, 8158, 354, 10, 32, 58, 35, 387, 14, 2752, 163, 19, 473, 13, 31, 9, 24, 264, 124, 182, 3], [2, 21, 7, 6391, 7, 551, 21, 715, 13, 12, 3791, 341, 175, 7, 980, 260, 49, 751, 17, 53, 27, 12, 145, 129, 6969, 47, 57, 219, 19662, 49, 15, 12, 850, 9, 7, 19, 874, 507, 15, 59, 1354, 1375, 5265, 11, 1354, 1375, 711, 10, 711, 10, 11, 69, 711, 9, 7, 32, 259, 98, 14, 84, 8, 361, 93, 4316, 196, 13, 298, 26, 46, 711, 34, 8, 2625, 10, 711, 11, 320, 397, 1518, 10, 711, 11, 98, 12, 9710, 10, 711, 11, 1240, 11, 1240, 11, 711, 10, 711, 34, 2748, 7262, 10, 2836, 60, 11, 711, 10, 538, 9, 26, 32, 370, 2257, 1079, 28, 158, 14, 601, 9, 7, 8, 1586, 52537, 13, 12, 81, 15, 37, 6798, 14, 1430, 12, 31, 27, 378, 149, 389, 1086, 10, 12, 11346, 196, 10, 11, 74, 212, 10, 74, 880, 10, 74, 369, 55, 1037, 10, 74, 1250, 459, 92, 56, 11775, 0, 9, 36, 12643, 33, 3], [2, 7, 2727, 1676, 24394, 17, 7, 18275, 7, 18276, 41, 12, 214, 23, 2041, 74, 23, 10408, 7060, 27, 8, 7, 39764, 13, 7, 3832, 10, 30, 64, 575, 68, 8, 26787, 7, 4927, 480, 751, 28, 12, 764, 7, 2258, 27, 1857, 551, 10, 2161, 1122, 10, 11, 65, 10613, 1128, 34, 8, 951, 1804, 66, 3856, 7, 1109, 23, 7, 1677, 749, 61, 12, 7627, 15939, 258, 208, 12, 244, 26788, 209, 8, 7988, 9, 7, 16, 15, 70, 1250, 34, 8, 10135, 10, 30075, 23, 53, 1234, 10, 9902, 1586, 34, 81, 9, 7, 2926, 7, 16287, 36, 48, 24974, 563, 7061, 28, 7, 2486, 7, 8596, 33, 427, 16, 12, 8128, 10, 76, 174, 71, 22, 8058, 27, 11266, 7, 1698, 7, 17314, 36, 17, 12159, 113, 23, 72, 11, 4146, 1122, 33, 9, 7, 103, 67, 96, 7, 4357, 7, 18008, 26, 7, 2926, 22, 23447, 2989, 10, 12, 28295, 2062, 49, 22, 1359, 2457, 34, 8, 317, 10, 11, 7, 5905, 7, 7544, 417, 816, 36, 49, 345, 66, 33, 9, 7, 8, 1791, 692, 13, 7, 10078, 248, 52538, 8, 212, 754, 34, 8, 7, 1677, 23935, 10, 11, 65, 13, 8, 762, 374, 38, 203, 398, 9, 7, 47, 8, 75, 13, 8, 219, 0, 2005, 10, 110, 798, 105, 41, 85, 215, 9, 194, 382, 124, 264, 51, 4, 224, 194, 3]...]\n",
       "Path: C:\\Users\\cross-entropy\\.fastai\\data\\imdb\n",
       "y: ItemList (25000 items)\n",
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0...]\n",
       "Path: C:\\Users\\cross-entropy\\.fastai\\data\\imdb\n"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class '__main__.NumericalizeProcessor'>: it's not the same object as __main__.NumericalizeProcessor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-182-5c97e3050db0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;34m'll_clas.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <class '__main__.NumericalizeProcessor'>: it's not the same object as __main__.NumericalizeProcessor"
     ]
    }
   ],
   "source": [
    "pickle.dump(ll, open(path/'ll_clas.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-183-37e3bc0fe2e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;34m'll_clas.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "ll = pickle.load(open(path/'ll_clas.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the labels seem consistent with the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"xxbos xxmaj airport ' 77 starts as a brand new luxury 747 plane is loaded up with valuable paintings & such belonging to rich businessman xxmaj philip xxmaj stevens ( xxmaj james xxmaj stewart ) who is flying them & a bunch of vip 's to his estate in preparation of it being opened to the public as a museum , also on board is xxmaj stevens daughter xxmaj julie ( xxmaj kathleen xxmaj quinlan ) & her son . xxmaj the luxury xxunk takes off as planned but mid - air the plane is hi - jacked by the co - pilot xxmaj chambers ( xxmaj robert xxmaj foxworth ) & his two accomplice 's xxmaj banker ( xxmaj monte xxmaj markham ) & xxmaj wilson ( xxmaj michael xxmaj pataki ) who knock the passengers & crew out with sleeping gas , they plan to steal the valuable cargo & land on a disused plane strip on an isolated island but while making his descent xxmaj chambers almost hits an oil rig in the xxmaj ocean & loses control of the plane sending it crashing into the sea where it sinks to the bottom right bang in the middle of the xxmaj bermuda xxmaj triangle . xxmaj with air in short supply , water leaking in & having flown over 200 miles off course the problems mount for the survivor 's as they await help with time fast running out ... \\n\\n xxmaj also known under the slightly different tile xxmaj airport 1977 this second sequel to the smash - hit disaster thriller xxmaj airport ( 1970 ) was directed by xxmaj jerry xxmaj jameson & while once again like it 's predecessors i ca n't say xxmaj airport ' 77 is any sort of forgotten classic it is entertaining although not necessarily for the right reasons . xxmaj out of the three xxmaj airport films i have seen so far i actually liked this one the best , just . xxmaj it has my favourite plot of the three with a nice mid - air hi - jacking & then the crashing ( did n't he see the oil rig ? ) & sinking of the 747 ( maybe the makers were trying to cross the original xxmaj airport with another popular disaster flick of the period xxmaj the xxmaj poseidon xxmaj adventure ( 1972 ) ) & submerged is where it stays until the end with a stark dilemma facing those trapped inside , either suffocate when the air runs out or drown as the 747 floods or if any of the doors are opened & it 's a decent idea that could have made for a great little disaster flick but bad unsympathetic character 's , dull dialogue , lethargic set - pieces & a real lack of danger or suspense or tension means this is a missed opportunity . xxmaj while the rather sluggish plot keeps one entertained for 108 odd minutes not that much happens after the plane sinks & there 's not as much urgency as i thought there should have been . xxmaj even when the xxmaj navy become involved things do n't pick up that much with a few shots of huge ships & helicopters flying about but there 's just something lacking here . xxmaj george xxmaj kennedy as the jinxed airline worker xxmaj joe xxmaj patroni is back but only gets a couple of scenes & barely even says anything preferring to just look worried in the background . \\n\\n xxmaj the home video & theatrical version of xxmaj airport ' 77 run 108 minutes while the us tv versions add an extra hour of footage including a new opening credits sequence , many more scenes with xxmaj george xxmaj kennedy as xxmaj patroni , flashbacks to flesh out character 's , longer rescue scenes & the discovery or another couple of dead bodies including the navigator . xxmaj while i would like to see this extra footage i am not sure i could sit through a near three hour cut of xxmaj airport ' 77 . xxmaj as expected the film has dated badly with horrible fashions & interior design choices , i will say no more other than the toy plane model effects are n't great either . xxmaj along with the other two xxmaj airport sequels this takes pride of place in the xxmaj razzie xxmaj award 's xxmaj hall of xxmaj shame although i can think of lots of worse films than this so i reckon that 's a little harsh . xxmaj the action scenes are a little dull unfortunately , the pace is slow & not much excitement or tension is generated which is a shame as i reckon this could have been a pretty good film if made properly . \\n\\n xxmaj the production values are alright if nothing spectacular . xxmaj the acting is n't great , two time xxmaj oscar winner xxmaj jack xxmaj lemmon has said since it was a mistake to star in this , one time xxmaj oscar winner xxmaj james xxmaj stewart looks old & frail , also one time xxmaj oscar winner xxmaj lee xxmaj grant looks drunk while xxmaj sir xxmaj christopher xxmaj lee is given little to do & there are plenty of other familiar faces to look out for too . \\n\\n xxmaj airport ' 77 is the most disaster orientated of the three xxmaj airport films so far & i liked the ideas behind it even if they were a bit silly , the production & bland direction does n't help though & a film about a sunken plane just should n't be this boring or lethargic . xxmaj followed by xxmaj the xxmaj concorde ... xxmaj airport ' 79 ( 1979 ) . xxeos\",\n",
       "  'neg'),\n",
       " (\"xxbos xxmaj to all the miserable people who have done everything from complain about the dialogue , the budget , the this and the that xxrep 4 . who wants to hear it ? if you missed the point of this beyond - beautiful movie , that 's your loss . xxmaj the rest of us who deeply love this movie do not care what you think . i am a xxunk guy who has seen thousands of movies in my life , and this one stands in its own entity , in my book . xxmaj it was not supposed to be a documentary , or a completely factual account of what happened that night . xxmaj it is the most amazing love story ever attempted . i know that it is the cynical 90 's and the millennium has everyone in a tizzy , but come on . xxmaj someone on this comments board complained that it made too much money ! xxmaj how lame is that ? xxmaj it made bundles of money in every civilized country on the planet , and is the top grossing film in the planet . i will gladly side with the majority this time around . xxmaj okay , cynics , time to crawl back under your rock , i am done . xxeos\",\n",
       "  'pos')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(ll.train.x_obj(i), ll.train.y_obj(i)) for i in [1,12552]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw samplers in notebook 03. For the validation set, we will simply sort the samples by length, and we begin with the longest ones for memory reasons (it's better to always have the biggest tensors first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "class SortSampler(Sampler):\n",
    "    def __init__(self, data_source, key): self.data_source,self.key = data_source,key\n",
    "    def __len__(self): return len(self.data_source)\n",
    "    def __iter__(self):\n",
    "        return iter(sorted(list(range(len(self.data_source))), key=self.key, reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the training set, we want some kind of randomness on top of this. So first, we shuffle the texts and build megabatches of size `50 * bs`. We sort those megabatches by length before splitting them in 50 minibatches. That way we will have randomized batches of roughly the same length.\n",
    "\n",
    "Then we make sure to have the biggest batch first and shuffle the order of the other batches. We also make sure the last batch stays at the end because its size is probably lower than batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SortishSampler(Sampler):\n",
    "    def __init__(self, data_source, key, bs):\n",
    "        self.data_source,self.key,self.bs = data_source,key,bs\n",
    "\n",
    "    def __len__(self) -> int: return len(self.data_source)\n",
    "\n",
    "    def __iter__(self):\n",
    "        idxs = torch.randperm(len(self.data_source))\n",
    "        megabatches = [idxs[i:i+self.bs*50] for i in range(0, len(idxs), self.bs*50)]\n",
    "        sorted_idx = torch.cat([tensor(sorted(s, key=self.key, reverse=True)) for s in megabatches])\n",
    "        batches = [sorted_idx[i:i+self.bs] for i in range(0, len(sorted_idx), self.bs)]\n",
    "        max_idx = torch.argmax(tensor([self.key(ck[0]) for ck in batches]))  # find the chunk with the largest key,\n",
    "        batches[0],batches[max_idx] = batches[max_idx],batches[0]            # then make sure it goes first.\n",
    "        batch_idxs = torch.randperm(len(batches)-2)\n",
    "        sorted_idx = torch.cat([batches[i+1] for i in batch_idxs]) if len(batches) > 1 else LongTensor([])\n",
    "        sorted_idx = torch.cat([batches[0], sorted_idx, batches[-1]])\n",
    "        return iter(sorted_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding: we had the padding token (that has an id of 1) at the end of each sequence to make them all the same size when batching them. Note that we need padding at the end to be able to use `PyTorch` convenience functions that will let us ignore that padding (see 12c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def pad_collate(samples, pad_idx=1, pad_first=False):\n",
    "    max_len = max([len(s[0]) for s in samples])\n",
    "    res = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: res[i, -len(s[0]):] = LongTensor(s[0])\n",
    "        else:         res[i, :len(s[0]) ] = LongTensor(s[0])\n",
    "    return res, tensor([s[1] for s in samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "train_sampler = SortishSampler(ll.train.x, key=lambda t: len(ll.train[int(t)][0]), bs=bs)\n",
    "train_dl = DataLoader(ll.train, batch_size=bs, sampler=train_sampler, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_dl = iter(train_dl)\n",
    "x,y = next(iter_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3311, 1394, 1358, 1346, 1344], 1013)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = []\n",
    "for i in range(x.size(0)): lengths.append(x.size(1) - (x[i]==1).sum().item())\n",
    "lengths[:5], lengths[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last one is the minimal length. This is the first batch so it has the longest sequence, but if look at the next one that is more random, we see lengths are roughly the sames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([102, 102, 102, 101, 101], 92)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter_dl)\n",
    "lengths = []\n",
    "for i in range(x.size(0)): lengths.append(x.size(1) - (x[i]==1).sum().item())\n",
    "lengths[:5], lengths[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the padding at the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,    7,   19,  ...,  185,    9,    3],\n",
       "        [   2,    7,   19,  ...,  108,    9,    3],\n",
       "        [   2,    7, 5049,  ...,  676,    9,    3],\n",
       "        ...,\n",
       "        [   2,    7,   48,  ...,    1,    1,    1],\n",
       "        [   2,    7,   19,  ...,    1,    1,    1],\n",
       "        [   2,   18,   25,  ...,    1,    1,    1]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we add a convenience function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_clas_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    train_sampler = SortishSampler(train_ds.x, key=lambda t: len(train_ds.x[t]), bs=bs)\n",
    "    valid_sampler = SortSampler(valid_ds.x, key=lambda t: len(valid_ds.x[t]))\n",
    "    return (DataLoader(train_ds, batch_size=bs, sampler=train_sampler, collate_fn=pad_collate, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=bs*2, sampler=valid_sampler, collate_fn=pad_collate, **kwargs))\n",
    "\n",
    "def clas_databunchify(sd, bs, **kwargs):\n",
    "    return DataBunch(*get_clas_dls(sd.train, sd.valid, bs, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,bptt = 64,70\n",
    "data = clas_databunchify(ll, bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 12_text.ipynb to exp\\nb_12.py\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py 12_text.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
