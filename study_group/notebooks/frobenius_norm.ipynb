{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In words, the Frobenius norm of a matrix is the square root of the sums of the squares of all its elements; it provides a rough measure of the \"size\" of the matrix.\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Matrix_norm#Frobenius_norm) gives three ways of expressing the Frobenius norm of a matrix whose elements are real numbers:\n",
    "\n",
    "> $ \\|A\\|_{\\mathrm{F}}\\equiv \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n}\\left|a_{i j}\\right|^{2}}=\\sqrt{\\operatorname{trace}\\left(A^{T} A\\right)}=\\sqrt{\\sum_{i=1}^{\\min \\{m, n\\}} \\sigma_{i}^{2}(A)}$,\n",
    "\n",
    "where the superscript $^{T}$ refers to the transpose matrix, and the singular values $\\sigma_{i}(A)$ are the square roots of the eigenvalues of the matrix $A A^T$\n",
    "\n",
    "The third expression is the sum of the eigenvalues of  $A A^T$; although mathematically interesting, it's extraneous to this discussion because it's not the best way to compute the Frobenius norm. \n",
    "\n",
    "Let's demonstrate the equality of the 1st and 2nd expressions. Suppose $A$ is an $n\\times m$ matrix, i.e. $A$ has $n$  rows and $m$ columns. \n",
    "\n",
    "Then\n",
    "\n",
    "> $A^{T} A$ is an $m\\times m$ matrix whose diagonal elements are\n",
    "\n",
    "> $A_{j} \\cdot A_{j}$, where $j$ runs from $1$ to $m$, and\n",
    "\n",
    "> $A_{j} \\equiv (a_{1j},   ..., a_{nj})$ is the $jth$ column of $A$. \n",
    "\n",
    "The diagonal elements of $ A^{T} A $ are evidently the set of dot products of each column of $A$ with itself;\n",
    "\n",
    "> $\\operatorname{trace}\\left(A^{T} A\\right)$ is defined as the sum of the diagonal elements of $\\left(A^{T} A\\right)$, \n",
    "\n",
    "which is just the sum of the squares of all the elements of $A$.\n",
    "\n",
    "> QED\n",
    "\n",
    "It's interesting to note that  the *order* of the terms in the product of the matrix with its transpose doesn't matter, giving rise to an alternate form for the Frobenius norm:\n",
    "\n",
    "> $\\operatorname{trace}\\left(A^{T} A\\right) = \\operatorname{trace}\\left(A A^{T} \\right)$;\n",
    "\n",
    "$\\operatorname{trace}\\left( A^{T}A \\right)$ is the sum of $m$ dot products of the $n\\times1$ columns of $A$ with themselves, while $\\operatorname{trace}\\left(A A^{T} \\right)$ is the sum of $n$ dot products of the $m\\times1$ rows of $A$ with themselves. Evidently both expressions reduce to the Frobenius norm, and have computational complexity  of $O(mn)$, which is lower than that of the singular value decomposition required to compute $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
