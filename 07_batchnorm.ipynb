{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_06 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the data and training interface from where we left in the last notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 10 video](https://course.fast.ai/videos/?lesson=10&t=5899)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()\n",
    "\n",
    "x_train,x_valid = normalize_to(x_train,x_valid)\n",
    "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
    "\n",
    "nh,bs = 50,512\n",
    "c = y_train.max().item()+1\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_view = view_tfm(1,28,28)\n",
    "cbfs = [Recorder,\n",
    "        partial(AvgStatsCallback,accuracy),\n",
    "        CudaCallback,\n",
    "        partial(BatchTransformXCallback, mnist_view)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs = [8,16,32,64,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.4, conv_layer, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [1.25816140625, tensor(0.5759, device='cuda:0')]\n",
      "valid: [0.355390625, tensor(0.8830, device='cuda:0')]\n",
      "train: [0.236247890625, tensor(0.9289, device='cuda:0')]\n",
      "valid: [0.13106741943359376, tensor(0.9601, device='cuda:0')]\n",
      "Wall time: 7.18 s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(2, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batchnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by building our own `BatchNorm` layer from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 10 video](https://course.fast.ai/videos/?lesson=10&t=6018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, nf, mom=0.1, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # NB: pytorch bn mom is opposite of what you'd expect\n",
    "        self.mom,self.eps = mom,eps\n",
    "        self.mults = nn.Parameter(torch.ones (nf,1,1))\n",
    "        self.adds  = nn.Parameter(torch.zeros(nf,1,1))\n",
    "        self.register_buffer('vars',  torch.ones(1,nf,1,1))\n",
    "        self.register_buffer('means', torch.zeros(1,nf,1,1))\n",
    "\n",
    "    def update_stats(self, x):\n",
    "        m = x.mean((0,2,3), keepdim=True)\n",
    "        v = x.var ((0,2,3), keepdim=True)\n",
    "        self.means.lerp_(m, self.mom)\n",
    "        self.vars.lerp_ (v, self.mom)\n",
    "        return m,v\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            with torch.no_grad(): m,v = self.update_stats(x)\n",
    "        else: m,v = self.means,self.vars\n",
    "        x = (x-m) / (v+self.eps).sqrt()\n",
    "        return x*self.mults + self.adds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(ni, nf, ks=3, stride=2, bn=True, **kwargs):\n",
    "    # No bias needed if using bn\n",
    "    layers = [nn.Conv2d(ni, nf, ks, padding=ks//2, stride=stride, bias=not bn),\n",
    "              GeneralRelu(**kwargs)]\n",
    "    if bn: layers.append(BatchNorm(nf))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def init_cnn_(m, f):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        f(m.weight, a=0.1)\n",
    "        if getattr(m, 'bias', None) is not None: m.bias.data.zero_()\n",
    "    for l in m.children(): init_cnn_(l, f)\n",
    "\n",
    "def init_cnn(m, uniform=False):\n",
    "    f = init.kaiming_uniform_ if uniform else init.kaiming_normal_\n",
    "    init_cnn_(m, f)\n",
    "\n",
    "def get_learn_run(nfs, data, lr, layer, cbs=None, opt_func=None, uniform=False, **kwargs):\n",
    "    model = get_cnn_model(data, nfs, layer, **kwargs)\n",
    "    init_cnn(model, uniform=uniform)\n",
    "    return get_runner(model, data, lr=lr, cbs=cbs, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use it in training and see how it helps keep the activations means to 0 and the std to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.9, conv_layer, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-fb2bbdd9c29f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mHooks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappend_stats\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0max1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\fastai\\course-v3\\nbs\\dl2\\exp\\nb_05b.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, epochs, learn)\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'begin_epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\fastai\\course-v3\\nbs\\dl2\\exp\\nb_05b.py\u001b[0m in \u001b[0;36mall_batches\u001b[1;34m(self, dl)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdl\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'after_cancel_epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\fastai\\course-v3\\nbs\\dl2\\exp\\nb_05b.py\u001b[0m in \u001b[0;36mone_batch\u001b[1;34m(self, xb, yb)\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'begin_batch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'after_pred'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    547\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\fastai\\course-v3\\nbs\\dl2\\exp\\nb_06.py\u001b[0m in \u001b[0;36mappend_stats\u001b[1;34m(hook, mod, inp, outp)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'stats'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mmeans\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[0mmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mstds\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "with Hooks(learn.model, append_stats) as hooks:\n",
    "    run.fit(1, learn)\n",
    "    fig,(ax0,ax1) = plt.subplots(1,2, figsize=(10,4))\n",
    "    for h in hooks[:-1]:\n",
    "        ms,ss = h.stats\n",
    "        ax0.plot(ms[:10])\n",
    "        ax1.plot(ss[:10])\n",
    "        h.remove()\n",
    "    plt.legend(range(6));\n",
    "    \n",
    "    fig,(ax0,ax1) = plt.subplots(1,2, figsize=(10,4))\n",
    "    for h in hooks[:-1]:\n",
    "        ms,ss = h.stats\n",
    "        ax0.plot(ms)\n",
    "        ax1.plot(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 1.0, conv_layer, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.2704182421875, tensor(0.9166, device='cuda:0')]\n",
      "valid: [0.4613767578125, tensor(0.8538, device='cuda:0')]\n",
      "train: [0.08982197265625, tensor(0.9733, device='cuda:0')]\n",
      "valid: [0.09036126098632813, tensor(0.9739, device='cuda:0')]\n",
      "train: [0.065138642578125, tensor(0.9804, device='cuda:0')]\n",
      "valid: [0.34381416015625, tensor(0.8860, device='cuda:0')]\n",
      "Wall time: 7.16 s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Builtin batchnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 10 video](https://course.fast.ai/videos/?lesson=10&t=6679)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def conv_layer(ni, nf, ks=3, stride=2, bn=True, **kwargs):\n",
    "    layers = [nn.Conv2d(ni, nf, ks, padding=ks//2, stride=stride, bias=not bn),\n",
    "              GeneralRelu(**kwargs)]\n",
    "    if bn: layers.append(nn.BatchNorm2d(nf, eps=1e-5, momentum=0.1))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 1., conv_layer, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.22281953125, tensor(0.9304, device='cuda:0')]\n",
      "valid: [0.09529148559570312, tensor(0.9706, device='cuda:0')]\n",
      "train: [0.068677119140625, tensor(0.9779, device='cuda:0')]\n",
      "valid: [0.0807756591796875, tensor(0.9759, device='cuda:0')]\n",
      "train: [0.047551357421875, tensor(0.9855, device='cuda:0')]\n",
      "valid: [0.0841427001953125, tensor(0.9741, device='cuda:0')]\n",
      "Wall time: 5.82 s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the usual warm-up/annealing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = combine_scheds([0.3, 0.7], [sched_lin(0.6, 2.), sched_lin(2., 0.1)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.9, conv_layer, cbs=cbfs\n",
    "                          +[partial(ParamScheduler,'lr', sched)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.23340701171875, tensor(0.9297, device='cuda:0')]\n",
      "valid: [0.154277099609375, tensor(0.9515, device='cuda:0')]\n",
      "train: [0.085291748046875, tensor(0.9735, device='cuda:0')]\n",
      "valid: [0.07003228759765626, tensor(0.9786, device='cuda:0')]\n",
      "train: [0.0531568310546875, tensor(0.9833, device='cuda:0')]\n",
      "valid: [0.07565449829101563, tensor(0.9763, device='cuda:0')]\n",
      "train: [0.03460838623046875, tensor(0.9892, device='cuda:0')]\n",
      "valid: [0.05115161743164062, tensor(0.9852, device='cuda:0')]\n",
      "train: [0.0205441796875, tensor(0.9940, device='cuda:0')]\n",
      "valid: [0.04334853515625, tensor(0.9875, device='cuda:0')]\n",
      "train: [0.011843660888671875, tensor(0.9967, device='cuda:0')]\n",
      "valid: [0.03951585083007812, tensor(0.9886, device='cuda:0')]\n",
      "train: [0.0067177685546875, tensor(0.9987, device='cuda:0')]\n",
      "valid: [0.037521337890625, tensor(0.9892, device='cuda:0')]\n",
      "train: [0.004585076904296875, tensor(0.9994, device='cuda:0')]\n",
      "valid: [0.03831666259765625, tensor(0.9891, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "run.fit(8, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [the paper](https://arxiv.org/abs/1607.06450): \"*batch normalization cannot be applied to online learning tasks or to extremely large distributed models where the minibatches have to be small*\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General equation for a norm layer with learnable affine:\n",
    "\n",
    "$$y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta$$\n",
    "\n",
    "The difference with BatchNorm is\n",
    "1. we don't keep a moving average\n",
    "2. we don't average over the batches dimension but over the hidden dimension, so it's independent of the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 10 video](https://course.fast.ai/videos/?lesson=10&t=6717)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    __constants__ = ['eps']\n",
    "    def __init__(self, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.mult = nn.Parameter(tensor(1.))\n",
    "        self.add  = nn.Parameter(tensor(0.))\n",
    "\n",
    "    def forward(self, x):\n",
    "        m = x.mean((1,2,3), keepdim=True)\n",
    "        v = x.var ((1,2,3), keepdim=True)\n",
    "        x = (x-m) / ((v+self.eps).sqrt())\n",
    "        return x*self.mult + self.add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_ln(ni, nf, ks=3, stride=2, bn=True, **kwargs):\n",
    "    layers = [nn.Conv2d(ni, nf, ks, padding=ks//2, stride=stride, bias=True),\n",
    "              GeneralRelu(**kwargs)]\n",
    "    if bn: layers.append(LayerNorm())\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.8, conv_ln, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [nan, tensor(0.1300, device='cuda:0')]\n",
      "valid: [nan, tensor(0.0991, device='cuda:0')]\n",
      "train: [nan, tensor(0.0986, device='cuda:0')]\n",
      "valid: [nan, tensor(0.0991, device='cuda:0')]\n",
      "train: [nan, tensor(0.0986, device='cuda:0')]\n",
      "valid: [nan, tensor(0.0991, device='cuda:0')]\n",
      "Wall time: 9.66 s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Thought experiment*: can this distinguish foggy days from sunny days (assuming you're using it before the first conv)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [the paper](https://arxiv.org/abs/1607.08022): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key difference between **contrast** and batch normalization is that the latter applies the normalization to a  whole batch of images instead for single ones:\n",
    "\n",
    "\\begin{equation}\\label{eq:bnorm}\n",
    "    y_{tijk} =  \\frac{x_{tijk} - \\mu_{i}}{\\sqrt{\\sigma_i^2 + \\epsilon}},\n",
    "    \\quad\n",
    "    \\mu_i = \\frac{1}{HWT}\\sum_{t=1}^T\\sum_{l=1}^W \\sum_{m=1}^H x_{tilm},\n",
    "    \\quad\n",
    "    \\sigma_i^2 = \\frac{1}{HWT}\\sum_{t=1}^T\\sum_{l=1}^W \\sum_{m=1}^H (x_{tilm} - mu_i)^2.\n",
    "\\end{equation}\n",
    "\n",
    "In order to combine the effects of instance-specific normalization and batch normalization, we propose to replace the latter by the *instance normalization* (also known as *contrast normalization*) layer:\n",
    "\n",
    "\\begin{equation}\\label{eq:inorm}\n",
    "    y_{tijk} =  \\frac{x_{tijk} - \\mu_{ti}}{\\sqrt{\\sigma_{ti}^2 + \\epsilon}},\n",
    "    \\quad\n",
    "    \\mu_{ti} = \\frac{1}{HW}\\sum_{l=1}^W \\sum_{m=1}^H x_{tilm},\n",
    "    \\quad\n",
    "    \\sigma_{ti}^2 = \\frac{1}{HW}\\sum_{l=1}^W \\sum_{m=1}^H (x_{tilm} - mu_{ti})^2.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 10 video](https://course.fast.ai/videos/?lesson=10&t=7114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceNorm(nn.Module):\n",
    "    __constants__ = ['eps']\n",
    "    def __init__(self, nf, eps=1e-0):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.mults = nn.Parameter(torch.ones (nf,1,1))\n",
    "        self.adds  = nn.Parameter(torch.zeros(nf,1,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        m = x.mean((2,3), keepdim=True)\n",
    "        v = x.var ((2,3), keepdim=True)\n",
    "        res = (x-m) / ((v+self.eps).sqrt())\n",
    "        return res*self.mults + self.adds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_in(ni, nf, ks=3, stride=2, bn=True, **kwargs):\n",
    "    layers = [nn.Conv2d(ni, nf, ks, padding=ks//2, stride=stride, bias=True),\n",
    "              GeneralRelu(**kwargs)]\n",
    "    if bn: layers.append(InstanceNorm(nf))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.1, conv_in, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [nan, tensor(0.0986, device='cuda:0')]\n",
      "valid: [nan, tensor(0.0991, device='cuda:0')]\n",
      "train: [nan, tensor(0.0986, device='cuda:0')]\n",
      "valid: [nan, tensor(0.0991, device='cuda:0')]\n",
      "train: [nan, tensor(0.0986, device='cuda:0')]\n",
      "valid: [nan, tensor(0.0991, device='cuda:0')]\n",
      "Wall time: 9.52 s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question*: why can't this classify anything?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lost in all those norms? The authors from the [group norm paper](https://arxiv.org/pdf/1803.08494.pdf) have you covered:\n",
    "\n",
    "![Various norms](images/norms.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 10 video](https://course.fast.ai/videos/?lesson=10&t=7213)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*From the PyTorch docs:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GroupNorm(num_groups, num_channels, eps=1e-5, affine=True)`\n",
    "\n",
    "The input channels are separated into `num_groups` groups, each containing\n",
    "``num_channels / num_groups`` channels. The mean and standard-deviation are calculated\n",
    "separately over the each group. $\\gamma$ and $\\beta$ are learnable\n",
    "per-channel affine transform parameter vectorss of size `num_channels` if\n",
    "`affine` is ``True``.\n",
    "\n",
    "This layer uses statistics computed from input data in both training and\n",
    "evaluation modes.\n",
    "\n",
    "Args:\n",
    "-    num_groups (int): number of groups to separate the channels into\n",
    "-    num_channels (int): number of channels expected in input\n",
    "-    eps: a value added to the denominator for numerical stability. Default: 1e-5\n",
    "-    affine: a boolean value that when set to ``True``, this module\n",
    "        has learnable per-channel affine parameters initialized to ones (for weights)\n",
    "        and zeros (for biases). Default: ``True``.\n",
    "\n",
    "Shape:\n",
    "- Input: `(N, num_channels, *)`\n",
    "- Output: `(N, num_channels, *)` (same shape as input)\n",
    "\n",
    "Examples::\n",
    "\n",
    "    >>> input = torch.randn(20, 6, 10, 10)\n",
    "    >>> # Separate 6 channels into 3 groups\n",
    "    >>> m = nn.GroupNorm(3, 6)\n",
    "    >>> # Separate 6 channels into 6 groups (equivalent with InstanceNorm)\n",
    "    >>> m = nn.GroupNorm(6, 6)\n",
    "    >>> # Put all 6 channels into a single group (equivalent with LayerNorm)\n",
    "    >>> m = nn.GroupNorm(1, 6)\n",
    "    >>> # Activating the module\n",
    "    >>> output = m(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix small batch sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we compute the statistics (mean and std) for a BatchNorm Layer on a small batch, it is possible that we get a standard deviation very close to 0. because there aren't many samples (the variance of one thing is 0. since it's equal to its mean)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 10 video](https://course.fast.ai/videos/?lesson=10&t=7304)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(*get_dls(train_ds, valid_ds, 2), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(ni, nf, ks=3, stride=2, bn=True, **kwargs):\n",
    "    layers = [nn.Conv2d(ni, nf, ks, padding=ks//2, stride=stride, bias=not bn),\n",
    "              GeneralRelu(**kwargs)]\n",
    "    if bn: layers.append(nn.BatchNorm2d(nf, eps=1e-5, momentum=0.1))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.4, conv_layer, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [2.3159390625, tensor(0.2066, device='cuda:0')]\n",
      "valid: [31177.4656, tensor(0.3191, device='cuda:0')]\n",
      "Wall time: 4min 39s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Batch Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this problem we introduce a Running BatchNorm that uses smoother running mean and variance for the mean and std."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 10 video](https://course.fast.ai/videos/?lesson=10&t=7516)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunningBatchNorm(nn.Module):\n",
    "    def __init__(self, nf, mom=0.1, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.mom,self.eps = mom,eps\n",
    "        self.mults = nn.Parameter(torch.ones (nf,1,1))\n",
    "        self.adds = nn.Parameter(torch.zeros(nf,1,1))\n",
    "        self.register_buffer('sums', torch.zeros(1,nf,1,1))\n",
    "        self.register_buffer('sqrs', torch.zeros(1,nf,1,1))\n",
    "        self.register_buffer('batch', tensor(0.))\n",
    "        self.register_buffer('count', tensor(0.))\n",
    "        self.register_buffer('step', tensor(0.))\n",
    "        self.register_buffer('dbias', tensor(0.))\n",
    "\n",
    "    def update_stats(self, x):\n",
    "        bs,nc,*_ = x.shape\n",
    "        self.sums.detach_()\n",
    "        self.sqrs.detach_()\n",
    "        dims = (0,2,3)\n",
    "        s = x.sum(dims, keepdim=True)\n",
    "        ss = (x*x).sum(dims, keepdim=True)\n",
    "        c = self.count.new_tensor(x.numel()/nc)\n",
    "        mom1 = 1 - (1-self.mom)/math.sqrt(bs-1)\n",
    "        self.mom1 = self.dbias.new_tensor(mom1)\n",
    "        self.sums.lerp_(s, self.mom1)\n",
    "        self.sqrs.lerp_(ss, self.mom1)\n",
    "        self.count.lerp_(c, self.mom1)\n",
    "        self.dbias = self.dbias*(1-self.mom1) + self.mom1\n",
    "        self.batch += bs\n",
    "        self.step += 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training: self.update_stats(x)\n",
    "        sums = self.sums\n",
    "        sqrs = self.sqrs\n",
    "        c = self.count\n",
    "        if self.step<100:\n",
    "            sums = sums / self.dbias\n",
    "            sqrs = sqrs / self.dbias\n",
    "            c    = c    / self.dbias\n",
    "        means = sums/c\n",
    "        vars = (sqrs/c).sub_(means*means)\n",
    "        if bool(self.batch < 20): vars.clamp_min_(0.01)\n",
    "        x = (x-means).div_((vars.add_(self.eps)).sqrt())\n",
    "        return x.mul_(self.mults).add_(self.adds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_rbn(ni, nf, ks=3, stride=2, bn=True, **kwargs):\n",
    "    layers = [nn.Conv2d(ni, nf, ks, padding=ks//2, stride=stride, bias=not bn),\n",
    "              GeneralRelu(**kwargs)]\n",
    "    if bn: layers.append(RunningBatchNorm(nf))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.4, conv_rbn, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.4447709375, tensor(0.8861, device='cuda:0')]\n",
      "valid: [0.1501086669921875, tensor(0.9685, device='cuda:0')]\n",
      "Wall time: 12min 1s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solves the small batch size issue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can we do in a single epoch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see with a decent batch size what result we can get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 10 video](https://course.fast.ai/videos/?lesson=10&t=8068)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(*get_dls(train_ds, valid_ds, 32), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn,run = get_learn_run(nfs, data, 0.9, conv_rbn, cbs=cbfs\n",
    "                          +[partial(ParamScheduler,'lr', sched_lin(1., 0.2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.166983125, tensor(0.9479, device='cuda:0')]\n",
      "valid: [0.2398085693359375, tensor(0.9696, device='cuda:0')]\n",
      "Wall time: 48 s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "{\n",
       "const ip = IPython.notebook\n",
       "if (ip) {\n",
       "    ip.save_notebook()\n",
       "    console.log('a')\n",
       "    const s = `!python notebook2script.py ${ip.notebook_name}`\n",
       "    if (ip.kernel) { ip.kernel.execute(s) }\n",
       "}\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_auto_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
